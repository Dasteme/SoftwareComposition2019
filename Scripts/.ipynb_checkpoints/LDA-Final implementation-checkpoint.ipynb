{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\3des.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\aes.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\bouncycastle.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\cng.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\crypto++.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\cryptoapi.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\cryptographic-hash-function.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\cryptography.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\cryptojs.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\des.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\diffie-hellman.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\digital-signature.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\ecdsa.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\elliptic-curve.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\encryption-asymmetric.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\encryption-symmetric.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\encryption.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\hash.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\hmac.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\jce.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\keystore.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\md5.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\openssl.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\pbkdf2.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\pkcs#11.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\pkcs#7.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\private-key.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\public-key-encryption.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\public-key.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\pycrypto.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\rijndael.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\rsa.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\salt.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\sha.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\sha1.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\sha256.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\smartcard.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\x509.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\x509certificate.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020\\xor.csv\n",
      "**************************************************\n",
      "Dokument ignoriert: titl\n",
      "viewCount: viewcount\n",
      "commentCount: CommentCount\n",
      "favoriteCount: FavoriteCount\n",
      "score: score\n",
      "**************************************************\n",
      "269988\n"
     ]
    }
   ],
   "source": [
    "# ****************************************************************************************************\n",
    "# \n",
    "# Script that generates documents out of the downloaded CSV-files from Stackoverflow\n",
    "# \n",
    "# ****************************************************************************************************\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "# ********************\n",
    "# Some Variables\n",
    "# ********************\n",
    "\n",
    "# Settings\n",
    "csvdir = 'D:/Uni Bern/7. Semester/Software Composition/Github/SoftwareComposition2019/Stackoverflow_posts_19.01.2020/*.csv'\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "cachedStopwords = stopwords.words('english')\n",
    "\n",
    "# Results\n",
    "documents = []\n",
    "documents_addons = [] # Hold some additional information of the documents, like meta-info of the documents\n",
    "stemmed_words = []\n",
    "\n",
    "# Temporal Variables\n",
    "current_document = [] #An Array of Strings, like [\"title\", \"question\", \"answer1\", \"answer2\", ...]\n",
    "current_post_link = \"\"\n",
    "current_addons = []\n",
    "current_accepted_answer = \"\"\n",
    "current_startdate = \"\"\n",
    "\n",
    "current_enddate = \"\"\n",
    "\n",
    "\n",
    "# ********************\n",
    "# Some classes\n",
    "# ********************\n",
    "class Document_addons:\n",
    "            \n",
    "    def setValues(self, csvFileName, post_link_id, viewCount, commentCount, favoriteCount, score, answerCount, responseTimeInSeconds):\n",
    "        self.csvFileName = csvFileName\n",
    "        self.post_link_id = post_link_id\n",
    "        self.responseTimeInSeconds = int(responseTimeInSeconds)\n",
    "        \n",
    "        try:\n",
    "            self.viewCount = 0 if viewCount=='' else int(viewCount)\n",
    "            self.commentCount = 0 if commentCount=='' else int(commentCount)\n",
    "            self.favoriteCount = 0 if favoriteCount=='' else int(favoriteCount)\n",
    "            self.score = 0 if score=='' else int(score)\n",
    "            self.answerCount = int(answerCount)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "# ********************\n",
    "# Some functions\n",
    "# ********************\n",
    "\n",
    "# Starts a new document\n",
    "def generate_document(newPostRow):\n",
    "    global current_document\n",
    "    global current_post_link\n",
    "    global current_addons\n",
    "    global current_accepted_answer\n",
    "    global current_startdate\n",
    "    #print(\"Generating document for: \" + newPostRow[0]);\n",
    "    current_document = [newPostRow[1], newPostRow[2]]; # Adding title and question\n",
    "    current_post_link = newPostRow[0]\n",
    "    current_addons = [newPostRow[5], newPostRow[12], newPostRow[13], newPostRow[7]]\n",
    "    current_accepted_answer = newPostRow[11]\n",
    "    current_startdate = newPostRow[17]\n",
    "\n",
    "# Adds an answer to the current building document\n",
    "def add_answer(answerRow):\n",
    "    global current_document\n",
    "    global current_accepted_answer\n",
    "    global current_enddate\n",
    "    current_document.append(answerRow[3]);\n",
    "    if (answerRow[4] == current_accepted_answer):\n",
    "        current_enddate = answerRow[20]\n",
    "\n",
    "# Finishes the current building document\n",
    "def finish_document(csvFileName):\n",
    "    global current_document\n",
    "    global current_post_link\n",
    "    global current_addons\n",
    "    global current_startdate\n",
    "    global current_enddate\n",
    "    apply_stopwords(current_document)\n",
    "    apply_stemmer(current_document)\n",
    "    add_stemmed_words_to_statistics(current_document)\n",
    "    \n",
    "    newDocAddons = Document_addons()\n",
    "    if current_enddate != \"\":\n",
    "        timeDelay = (datetime.datetime.fromisoformat(current_enddate) - datetime.datetime.fromisoformat(current_startdate)).total_seconds()\n",
    "    else:\n",
    "        timeDelay = 0\n",
    "    if(newDocAddons.setValues(csvFileName,\n",
    "                              current_post_link,\n",
    "                              current_addons[0],\n",
    "                              current_addons[1],\n",
    "                              current_addons[2],\n",
    "                              current_addons[3],\n",
    "                              len(current_document)-2,\n",
    "                              timeDelay\n",
    "                             )):\n",
    "        documents.append(\" \".join(current_document))\n",
    "        documents_addons.append(newDocAddons)\n",
    "    else:\n",
    "        print (\"Dokument ignoriert: \" + current_document[0])\n",
    "        print (\"viewCount: \" + current_addons[0])\n",
    "        print (\"commentCount: \" + current_addons[1])\n",
    "        print (\"favoriteCount: \" + current_addons[2])\n",
    "        print (\"score: \" + current_addons[3])\n",
    "        \n",
    "    current_post_link = \"\"\n",
    "    current_enddate = \"\"\n",
    "    \n",
    "\n",
    "def apply_stemmer(array):\n",
    "    for i in range(0, len(array)):\n",
    "        array[i] = ' '.join([stemmer.stem(word) for word in array[i].split(' ')])\n",
    "        \n",
    "def apply_stopwords(array):\n",
    "    for i in range(0, len(array)):\n",
    "        array[i] = ' '.join([word for word in array[i].split(' ') if word not in cachedStopwords])\n",
    "        \n",
    "def add_stemmed_words_to_statistics(array):\n",
    "    for i in range(0, len(array)):\n",
    "        stemmed_words.extend([word for word in array[i].split(' ') if word not in stemmed_words])\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# ********************\n",
    "# Start\n",
    "# ********************\n",
    "\n",
    "csvs = glob.glob(csvdir)\n",
    "\n",
    "# For every CSV-File in the folder\n",
    "csvFileCounter = 0\n",
    "for c in csvs:\n",
    "    csvFileCounter = csvFileCounter+1\n",
    "    file = c.replace('\\\\', '/', 1)\n",
    "    print (c)\n",
    "    \n",
    "    # Open file and read it\n",
    "    f = open(file, encoding='utf8')\n",
    "    csvreader = csv.reader(f, delimiter=',', quotechar=\"\\\"\", quoting=csv.QUOTE_ALL)\n",
    "    \n",
    "    print(\"**************************************************\");\n",
    "    \n",
    "    # For every row in the CSV-File\n",
    "    documentCounter = 0;\n",
    "    lineCounter = -1\n",
    "    for row in csvreader:\n",
    "        lineCounter = lineCounter+1\n",
    "        #row[1] = \"title\"\n",
    "        #row[2] = \"question\"\n",
    "        #row[3] = \"answer\"\n",
    "        \n",
    "        \n",
    "        # Remove newlines to make the removing of code blocks work better (a \\n in the regex worked, but was not very safe)\n",
    "        row[1] = re.sub(r'\\n', r' ', row[1])\n",
    "        row[2] = re.sub(r'\\n', r' ', row[2])\n",
    "        row[3] = re.sub(r'\\n', r' ', row[3])\n",
    "        \n",
    "        \n",
    "        #Remove code block, before BeatifulSoup because otherwise the code-blocks are not there anymore\n",
    "        row[1] = re.sub(r'<code>.*<\\/code>', r' ', row[1])\n",
    "        row[2] = re.sub(r'<code>.*<\\/code>', r' ', row[2])\n",
    "        row[3] = re.sub(r'<code>.*<\\/code>', r' ', row[3])\n",
    "        \n",
    "        \n",
    "        # Apply BeatifulSoup\n",
    "        row[1] = BeautifulSoup(row[1], 'html.parser').get_text()\n",
    "        row[2] = BeautifulSoup(row[2], 'html.parser').get_text()\n",
    "        row[3] = BeautifulSoup(row[3], 'html.parser').get_text()\n",
    "        \n",
    "        \n",
    "        # Remove non-alphabetic chars, note: AFTER BeatufulSoup\n",
    "        row[1] = re.sub(r'[^a-zA-Z0-9 ]*', r'', row[1])\n",
    "        row[2] = re.sub(r'[^a-zA-Z0-9 ]*', r'', row[2])\n",
    "        row[3] = re.sub(r'[^a-zA-Z0-9 ]*', r'', row[3])\n",
    "        \n",
    "        \n",
    "        #Remove digits, AFTER BeautifulSoup AND AFTER non-alpha-chars (Because otherwise the digit may not be enclosed by spaces, but \"< or >\")\n",
    "        #Note: I'd like to replace by a ' ' instead of nothing, but then the mathc doesn't work anymore somehow\n",
    "        row[1] = re.sub(r' [\\d]+ ', r'', row[1])\n",
    "        row[2] = re.sub(r' [\\d]+ ', r'', row[2])\n",
    "        row[3] = re.sub(r' [\\d]+ ', r'', row[3])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Remove numbers at the start and end - doesn't work\n",
    "        #row[1] = re.sub(r' [\\d]+$', r' ', row[1])\n",
    "        #row[2] = re.sub(r' [\\d]+$', r' ', row[2])\n",
    "        #row[3] = re.sub(r' [\\d]+$', r' ', row[3])\n",
    "        #row[1] = re.sub(r'^[\\d]+ ', r' ', row[1])\n",
    "        #row[2] = re.sub(r'^[\\d]+ ', r' ', row[2])\n",
    "        #row[3] = re.sub(r'^[\\d]+ ', r' ', row[3])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Do some final stuff\n",
    "        row[1] = re.sub(r'[ ]+', r' ', row[1])\n",
    "        row[2] = re.sub(r'[ ]+', r' ', row[2])\n",
    "        row[3] = re.sub(r'[ ]+', r' ', row[3])\n",
    "        \n",
    "        #row[1] = re.sub(' [0-9]+ ', '', row[1])\n",
    "        #row[2] = re.sub(' [0-9]+ ', '', row[2])\n",
    "        #row[3] = re.sub(' [0-9]+ ', '', row[3])\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        if (row[11])\n",
    "        #print(row[20])\n",
    "        x = datetime.datetime.fromisoformat(row[20])\n",
    "        print (x)\n",
    "        x2 = x+datetime.timedelta(days=10)\n",
    "        x3 = x2 - x\n",
    "        print (x3.total_seconds())\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (current_post_link == row[0]):\n",
    "            add_answer(row);\n",
    "        else:\n",
    "            if (lineCounter != 0):\n",
    "                finish_document(c)\n",
    "            generate_document(row);\n",
    "            add_answer(row);\n",
    "            documentCounter = documentCounter+1\n",
    "            #if documentCounter > 2:\n",
    "            #    break;\n",
    "        \n",
    "    \n",
    "    finish_document(c) # Because no new row appears, we have to manually finish the document  \n",
    "    print(\"**************************************************\");\n",
    "\n",
    "    \n",
    "#for i in range (0, len(documents_addons)):\n",
    "#    print(documents_addons[i].post_link_id + \": \" + str(documents_addons[i].responseTimeInSeconds / 60 / 60))\n",
    "    \n",
    "print(len(stemmed_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now calculating: 6 number of topics\n",
      "Preparing LDA ...\n",
      "Now using 1gram with TFIDF-Vectorizer\n",
      "****************************************\n",
      "[RQ1] LDA topics - TFIDF, 6 topics, 1gram\n",
      "****************************************\n",
      "Topic 0:\n",
      "encrypt decrypt use key string code rsa java php data byte ae pad encod tri im openssl work iv result\n",
      "Topic 1:\n",
      "password hash salt user encrypt use databas store secur key data server md5 login need way php want attack mysql\n",
      "Topic 2:\n",
      "hash valu array use string xor function number md5 code file like key rubi im want tri way object need\n",
      "Topic 3:\n",
      "certif key privat public use sign signatur card file openssl rsa x509 generat client server creat pem cert verifi ca\n",
      "Topic 4:\n",
      "openssl error use instal file tri ssl work server version connect run im librari compil command code problem certif issu\n",
      "Topic 5:\n",
      "keystor file android app imag upload apk fingerprint key devic googl sha1 sign encrypt keytool use play facebook video folder\n",
      "****************************************\n",
      "[[0.92404866 0.01518833 0.01520185 0.01518695 0.01520044 0.01517377]\n",
      " [0.89512425 0.02098529 0.02099339 0.02097664 0.02097227 0.02094815]\n",
      " [0.40644721 0.53394527 0.01490408 0.01492437 0.0149039  0.01487518]\n",
      " ...\n",
      " [0.0250602  0.02503581 0.8748202  0.02502884 0.02503874 0.02501621]\n",
      " [0.04377248 0.04370976 0.78143412 0.04369998 0.04371304 0.04367062]\n",
      " [0.04119724 0.04115731 0.79419896 0.04118336 0.04111883 0.04114431]]\n",
      "**************************************************\n",
      "[RQ1] Topic0 - Example documents\n",
      "**************************************************\n",
      "Document0\n",
      "Index: 0\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 20227\n",
      "how i use 3des encryptiondecrypt java everi method i write encod string java use 3des cant decrypt back origin string doe anyon simpl code snippet encod decod string back origin string i know im make silli mistak somewher code here ive work far note i return base64 text encrypt method i base64 unencod decrypt method i tri see i make mistak base64 part puzzl  your code fine except baseencod bit mention test reason output may made sens display raw byte array tostr byte array return intern java refer string represent content here version that teeni bit clean print kyle boon decod string  i hard time figur post help find right answer case when work financi messag iso8583 3des requir quit specif especi case desedecbcpkcs5pad combin wasnt solv problem after compar test result 3des calcul design financi world i found valu desedeecbnopad suit specif task here demo implement tripled class use bounci castl provid  here simpli static encryptdecrypt class bias bounci castl pad exampl jose lui mont de oca this one use desedeecbpkcs7pad i dont bother manual pad  here solut use javaxcrypto librari apach common codec librari encod decod base64   \n",
      "**************************************************\n",
      "Document1\n",
      "Index: 4\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 1400830\n",
      "net tripledescryptoserviceprovid equival java pleas dont ask i code net encryptdecrypt string data i need make exact funcion java i tri sever exampl desed crypt none give result class net i even though make net webserbvic behind ssl serv two method writen net stupid without exhaust posibl mayb java peopl relat area top head make thank  have made sure net code use pad java code i see pad specifi net code that i ask do happen sourc java code help find mistak  tri follow for actual usag i would get base64 librari like common codec use codec come bouncycastl  you got problem your key must bebyt want generat key materi net java the iv must block size isbyt tripl des in java need specifi default mode pad desedecbcnopad onc make chang abl decrypt java side  code follow first note a differ initi vector must chosen everi messag hardcod initi vector make sens the iv sent along cipher text messag recipi secret i use util class base64 encod you use output zqpzgqhpjxr41bc62bvqo7pqaxbbvn0v1trxcoc usernameherepasswordher \n",
      "**************************************************\n",
      "Document2\n",
      "Index: 8\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 8530312\n",
      "php equival java tripl des encryptiondecrypt am tri decrypt key encrypt java tripl des function use php mcrypt function luck find java code i want write php function equival decrypttext java function find difficulti generat exact iv valu generat java code encrypt requir decrypt  this php equival java code i copi pkcs5pad comment without indic encod this make code non portabl clear text contain non asciicharact umlaut java use systemdefault charact set if chang i certain would i recommend use utf8 side java php you hard code cipherkey use iv key im mean cryptoexpert feel wrong may open huge secur leak creat random iv concaten start end messag sinc size iv afaik equal blocksiz cipher remov much byte start end easili separ iv messag as key best use kind key deriv method generat key right size human generat password of cours fulfil given requir cant chang method  the answer almost good just revers anyway thank lot java sampl phpjava translat \n",
      "**************************************************\n",
      "Document3\n",
      "Index: 10\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 17465732\n",
      "how use three key tripl des3d java i found link stackoverflow use3desencryptiondecryptioninjavabut fact method use two parameterhg58yz3cr9  as per document simpli pass cipher key isbit long keysiz must equal toor a keysiz ofwil generat tripl des key withintermedi key keysiz ofwil generat tripl des key withintermedi key your code seem someth question make fact output md5 onlybit long copypast cryptograph code internet produc secur applic use static iv compromis sever reason cbc mode better ecb if use static key probabl consid generat random byte use secur random number generat instead deriv key short ascii string also absolut reason use tripl des instead ae new applic  in principl fornext loop generat des aba key seem correct note provid desed abyt key javaonward amount thing that said code youv shown leav lot desir i secur key generat password base key deriv function pbkdf use password string key compos two key instead three use tripl des tdea aba key iv set zero instead random password string short furthermor follow code mistak seen use call seem returnsha1 output onlybyt to generat 3desbytebit use des abc key password like string use pbkdf2 ad authent tag also import maninthemiddl attack pad oracl appli it would much secur much practic upgrad ae control algorithm use well \n",
      "**************************************************\n",
      "Document4\n",
      "Index: 11\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 1142477\n",
      "use mcrypt decrypt ciphertext 3des cbc mode i ciphertext encrypt 3des cbc mode im troubl decrypt i follow inform actual valu howev im sure feed three key algorithm i tri chain togeth like key1key2key3 revers order avail ani help would appreci   threecharact long keysexpectedkeys is38 the key like hex format  i found problem function end it combin convert key ivec token hex remov md5 hash decrypt key remov base64 decod result plain text the pad charact result plain text bit odd that strip away rtrim it may also worth note encrypt initi done jsp use standard java librari might use anyon els go java encrypt php decrypt thank help volkerk here function i end use includ hex function i havent ad \n",
      "**************************************************\n",
      "Document5\n",
      "Index: 13\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 11668531\n",
      "switch cbc mode tripl des encrypt im work mvc applic net secur sensit inform info webconfig ive got two function encrypt decrypt inform use tripl des howev im new succeed reach till help friend ask question the point im current stuck i add tdes iv initi vector end encrypt string also retriev decrypt i mean would identifi encrypt info iv initi vector star from how add retriev tdes iv initi vector encrypt string advis switch cbc mode instead ecb ecb doesnt support iv but i confus i switch cbc i realli need help regard long struck problem unabl fnid solut pleas help would appreci thankyou  to chang cbc amend code read generat iv pass paramet encrypt method the c document help when encrypt plain text prepend iv messag send whole thing when decrypt extract first eight byte incom messag use iv the rest messag form cyphertext \n",
      "**************************************************\n",
      "Document6\n",
      "Index: 14\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 1474801\n",
      "tripled encrypt net coldfus play nice im tri exchang encrypt data aspnet applic anoth develop cf app use tripled here cf code fictiti key iv cours net happi get 6byte array iv wantsbyt ani idea wrong prefer chang i could make vbnet code make work or fail differ approach would work better two environ  tri use utf8 encod password  the default cf seem desedeecbpkcs5pad vbnet desedecbcpkcs7 i sure two pad pkcs5 pkcs7 seem compat to get work either need chang mode ecb vbnet side \n",
      "**************************************************\n",
      "Document7\n",
      "Index: 15\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 1389670\n",
      "iphon 3des encrypt return wrong result i serious troubl commoncrypto function there two exist applic blackberri window mobil use tripled encrypt ecb mode data exchang on either encrypt result now i want implent 3des encrypt iphon applic i went straight commoncrypto httpwwwopensourceapplecomsourcecommoncryptocommoncrypto32207commoncryptocommoncryptorh i get result i use cbc mode correspond result java c anyway i want use ecb mode i dont get work paramet error show this call ecb mode i strip littl bit it seem i almost tri everi set twice differ encod error  can post error messag one best way troubleshoot stuff ive found take known input known key known output test vector compar byte expect output observ output what your probabl good way test output like translat output hexadecim base64 encod  i believ problem kccoptionecbmod alon enough you also need pad sinc block cypher if pass ie kccoptionpkcs7pad kccoptionecbmod work  i realis old question refer i think key pass nsstring the key instead convert hexadecim byte array this hextobyt nsstring extens provid need follow the key also twice long one givencharact hex iebyt \n",
      "**************************************************\n",
      "Document8\n",
      "Index: 18\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 24384394\n",
      "3des encrypt nodej return invalid iv length im quit new node run issu encrypt object instead return encrypt object expect the key iv ive remov encrypt type copi anoth file sake test i tri various string encrypt type still get error though differ length error my knowledg encrypt limit ive use previous much els unfortun im troubl find troubleshoot resourc node regard ani help would appreci edit experi des des3 yield result  from op edit solv work code i found make script guess combin key iv length encrypt type method encod type result correct string it last resort work \n",
      "**************************************************\n",
      "Document9\n",
      "Index: 20\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 2454715\n",
      "iphon 3des encrypt key length issu i bang head wall one i need code iphon applic encrypt adigit pin use 3des ecb mode transmiss webservic i believ written net i get valu encrypt use code howev match valu net web servic i believ issu encrypt key i suppli web servic develop ischaract long i see iphon sdk constant kcckeysize3d isso i suspect dont know commoncrypto api call use firstcharact suppli key is correct is ani way i get generat correct encrypt pin i output data byte encrypt prior base64 encod attempt match generat net code help net develop sent byte array output neither nonbase64 encod byte array final base64 encod string match  mayb need use pad tri set option  3des symmetr block cipher use 24byte key 3des encrypt 8byte block anoth 8byte block with 24byte key encrypt revers ie decrypt the key arbitrari sequenc byte that charact in particular one byte valu zero perfect legal similar input output may arbitrari byte if key given consist charact must transform appropri sequenc byte way sinc got 48charact key string andi exactlya plausibl guess key given hexadecim notat see contain digit letter f as pad 3des encrypt 8byte block when messag encrypt length distinct frombyt customari format split process messag encrypt number invoc 3des the two keyword pad chain pad ad extra byte end way byte unambigu remov length appropri eg multipl ofchain decid exact goe 3des invoc simpli split pad messag independ encrypt block known ecb weak if pin code containsdigit must convent four digit becom leastbyt fed 3des if iphon behav similar man page maco x describ code run success unless length multipl eight which mean code show convert 4digit pin 8byte buffer alreadi nontrivi transform for instanc code might put four digit four byte use ascii encod set four byte zero or mayb fail either way theinput bit 3des import get exact way server you inspect code well  well i manag resolv lot read comment stackoverflow there sever issu the key i given net develop wascharact this cours need read hex string convert tocharact instead i ad code complet routin follow i sure use quit specif implement i hope help someon \n",
      "**************************************************\n",
      "**************************************************\n",
      "[RQ1] Topic1 - Example documents\n",
      "**************************************************\n",
      "Document0\n",
      "Index: 129\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 6479452\n",
      "toadstudio password set file secur concern i need share connect set file toadstudio sqleditor i concern password store set file the file current look like it meant connect databas via ssh tunnel so concern way password store file look first line file i assum password encrypt tripl des in sampl password equal usernam dbusersshus sinc i share file instanc toadstudio decrypt origin plain text i guess toadstudio use hard code seed encrypt stuff im run state secret server id like bit reassur trivial easi someon obtain password plaintext base set file ani insight would appreci  that look like 3des honest secur averag app use look vnc store password day scari in case definit sound like your right track have actual test share file allow toad user connect use store info if probabl would fair easi though trivial someon get password that said 3des isnt realli adequ day fair breakabl someon suffici access machin steal file could easili keylog instal backdoor kind thing from secur standpoint attack suffici access get file probabl game anyway \n",
      "**************************************************\n",
      "Document1\n",
      "Index: 209\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 8168905\n",
      "crypt send hidden communic client server i applic winform client written c server applic written php i need valid oper client server when client send valid send server inform like licenseid info point info i dont want spoof i want prevent fake call server the first solut i use 3des prevent anyon see clear data i send via get post method php webserv the problem inform like licenseid other alway so even i encrypt 3des call encrypt word alway could easili spoof i want know possibl send data look differ get post method i decrypt webserv what i chang make call differ provid data updat i forgot say i cant use ssl  ssl enabl php server this prevent inform get may listen wire it sound like may solv issu  mayb could use random salt inform base key like current date pseudorandom salt use key client server then could crypt 3des you also use https crypt info get ssl certif \n",
      "**************************************************\n",
      "Document2\n",
      "Index: 424\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 9971532\n",
      "how use aesencrypt proper im tri use ae encrypt aesencrypt mysql user password i came bunch differ problem this sql queri i use store new user databas and final long password long salt thank  you encrypt password databas store present password databas see question lengthi explan  typic actual need revers encrypt password have abil inher decreas secur system instead use irrevers hash function i suggest sha256 larger produc string result etc  pleas consid use password hash instead cryptograph hash the goal differ see httpssecuritystackexchangecoma641525424 info password framework like mention httpsstackoverflowcoma6337021516813 take care lot detail like salt \n",
      "**************************************************\n",
      "Document3\n",
      "Index: 428\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 427821\n",
      "best way implement sftp server solut im current set commerci sftp server im look opinion setup im current think implement well recommend commerci secur ftp server softwar would best suit bear mind data im respons high sensit commentsfeedback much appreci here scenariobefor file upload file compress encrypt use aeswith saltfil upload client server sftp portto sftp serverfil download https client use one time password verif strongchar alphanumer password the specif implement im think for partabov connect open use host key match public key authent user namepassword combin the firewal side restrict allow static ip client server connect for partth client suppli user namepassword per user basi audit log jail account server encrypt password file suppli per file basi im tri appli two mode encrypt time except file rest server along dedic firewal side access control sftp server configur block ip address certain number fail attempt short time invalid password attempt lock user password polici implement etc i like think ive cover much possibl id love hear guy think implement for commerci server side thing ive narrow gloalscap sftp w ssh http modul jscape secur ftp server ill assess suitabl weekend experi either id love hear also  so what wrong openssh come linux bsds  sinc data clear import sensit client perspect id suggest consult secur profession homegrown solut typic combin underkil result mechan ineffici insecur consid the file preencrypt gain sftphttps encrypt session eg login your use pki upload otp download there risk expos password user id signific how transmit onetim password is transmiss secur keep mind lockout scheme temporari otherwis hacker disabl entir system lock account question ask what i protect from i protect what attack vector what likelihood risk breach onc youv answer question youll better idea implement in general your choic aes256 salt reason multifactor authent probabl better multipl iter encrypt it often thought someth plus someth know certif password requir access as far avail util mani offtheshelf packag secur easi use look openssh openvpn vsftp starter good luck pleas let us know method choos   this part ring alarm bellshav written code encryptioncompress how key manag you also say key password deriv use aesand salt give fals sens secur real key space much less also use term salt inappropri suggest weak you would better use well proven implement eg someth like pgp gpg also use pgp style public key encrypt file decent key manag secur sftp server matter lot less your file could encrypt rest the argument secur rest system convolut lot protocol authent scheme control would lot easier secur file robust best practic rest matter lot less also independ control \n",
      "**************************************************\n",
      "Document4\n",
      "Index: 447\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 7467798\n",
      "ae generat key password everi algorithm size is possibl write singl method generat valid key password aes128 aes192 aes256 im think someth like as i dont salt ive thought hardcod predefin one now i dont know option secur code predefin salt ant use pbkdf2 use truncat hash  truncat 256bit length key size need the key random generat use secur method pbkdf2 if doubt hash length evenrandomnessdistribut truncat you also see pbekeyspec allow option specifi key length  if a user select password typic poor entropi if password user select instead produc cryptograph strong rng use password hash password in case need pbkdf2 pbkdf2 realli last resort solut pleas also read lesson learn misconcept regard encrypt cryptolog \n",
      "**************************************************\n",
      "Document5\n",
      "Index: 466\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 10252449\n",
      "ae key random ae key may generat code key obtain method reliabl onli must generat special algorithm  you add random algorithm use securerandom  the ae key anybit it practic unguess whatev method creat for exampl way thin wrapper around byte transform key way no special algorithm  it sound like your tri generat ae key base password if case use javaxcryptosecretkeyfactori method pass javaxcryptospecpbekeyspec paramet the pbekeyspec allow specifi password argument constructor  to add answer i believ reason basic random function arent secur two reason slight statist bias accept nonsecur relat situat narrow distribut unaccept secur applic they seed system datetim even know when generat key poor accuraci month would signific reduc brute forc search space \n",
      "**************************************************\n",
      "Document6\n",
      "Index: 477\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 55643\n",
      "how i keep mysql databas secur im go implement way go im still confus one point how i keep encrypt key secur hardwir php script live server db seem like major secur hole what best practic solut  you think long hard whether realli need keep cc if dont great reason dont everi week hear compani compromis ccs stolen all compani made fatal flaw kept much inform keep cc transact clear after delet as far secur server best cours action secur hardwar use intern system socket mysql make sure block network access mysql server make sure your use system permiss mysql permiss allow littl access need for script might consid writeon authent there realli encrypt method foolproof alway need decrypt thus must store key this say shouldnt store key one locat detect system compromis destroy file render data useless  i agre dont cc dont need but realli make sure file access web you write binari would return key this way store clear text but server compromis still easi get  secur need depend applic exampl time cc use user log thin onlin store type scenario encrypt cc hash user plaintext password perus salt dedic cc salt store valu perman sinc your store valu time get valu user enter password log make sure good session expir garbag collect polici place situat appli pleas describ situat detail provid appropri answer  mysql six easi step secur sensit data stepremov wildcard grant tabl steprequir use secur password note use mysql secureauth option prevent use older less secur mysql password format stepcheck permiss configur file stepencrypt clientserv transmiss stepdis remot access stepact monitor mysql access log secur tool \n",
      "**************************************************\n",
      "Document7\n",
      "Index: 486\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 11527374\n",
      "encrypt rsa privat key aesin java i write secur file share applic java the general architectur look like user wish encrypt file secur share multipl user the applic generat random uuid client use aespassword encrypt data uuid the uuid rsa encrypt person public key onc per share user each encrypt uuid packet store part file custom file header the file upload server other access the user use privat key read ae encrypt key decrypt file here catch the user privat key must encrypt store server databas file access multipl locat the privat key encrypt user select password client prior upload server i would like use aesbit encrypt and i would like entir thing without reli bouncycastl librari 3rd parti librari it need use standard javalibrari i chosen use aesencrypt rsa rather someth like pgp can anyon find anyth inher insecur approach think effici way edit ok im updat question answer i get suggest i transmit privat key server the reason i need privat key server user need abl access data multipl client multipl locat ie iphon ipad work laptop home pc they want manag copi key devic devic even insecur store key server would end email point  the big problem use uuid although uuid sort guarante uniqu quit bit contain quit predict substanti amount remain constant across uuid generat singl machin as person get access exampl key probabl guess mani peopl key fair easili the part that problemat store user privat key server this make whole rest scheme relat fragil sinc access key obvious give access rest data it also appar mean youll normal decrypt data server user access data across network itll either need reencrypt transmiss decrypt userss machin els youll transmit data clear thus render encrypt useless edit as i think id id list public key server when client want share file client obtain public key client server it generat secur random key encrypt data key it encrypt random key public key client suppos abl access data put togeth stream transmit server the client download stream decrypt key privat key use decrypt data this mean client privat key remain truli privat never leav machin form all ever share rest world public key definit shouldnt caus secur problem with two obvious line attack random number generat rsa for random number generat id use java securerandom exact sort purpos intend memori serv pretti care examin signific break seem fair unlik i wont tri comment secur rsa for i think primari concern protocol encrypt algorithm proper suffic say rsa signific broken youd obvious need chang code youd lot compani with pretti much client store privat key secur i like smart card job quit altern from viewpoint server protocol longer realli factor though edita deal multipl devic i think id simpli treat devic separ user publicpriv key pair id probabl group togeth actual user i easili choos joe blow give access devic hierarch display i could also pretti easili restrict access subset i want share joe offic machin sensit enough i dont want go somebodi might look shoulder look i pretti easili this keep life simpl user retain basic secur model ie privat key remain privat  it depend secur want encrypt obvious rsa well documentaccept standard pki that said time provid plaintext well encrypt text make signific easier hacker decrypt ciphertext know part plaintext here precis although transmit encrypt uuid plaintext encrypt multipl key give attack signific insight payload furthermor hack actual one recipi abl decod uuid therebi automat know plaintext encrypt user public key this like critic issu thought i would point secur risk i entir sure need store user privat key howev furthermor use simpl password encrypt privat key basic reduc overal secur entir system strength user password final user lose password toast way recov data i someth similar past store result db howev i use bouncycastl librari time sure accomplish without  the scheme outlin equival cms standard under smime pgp fundament secur in cms mode call key transport you could also use multiparti key agreement algorithm like dh ecdh the problem use poor chosen key ae i cant think reason use random uuid contain nonrandom bit just use normal key generat mechan java cryptographi architectur key plaintext ciphertext repres byte sequenc unless need accommod extern storag transport accommod text have user select rememb password givebit effect strength unreason to get strength youd random choos password encod text user write card if realli need much strength could check smartcardbas solut store user rsa key id high recommend use cms librari store file it increas chanc protocol your use safe code use review tool librari system interoper encrypt messag bouncycastl api littl obscur might worth learn i cant rememb javasupport rsaecboaepwithsha512andmgf1pad use instead pkcs1pad  ok question ask protocol discuss complet accord stackoverflow standard that said let see make remark anyway the bounci castl pgp librari permiss licens even copi subpackag within code besid pgp also standard contain format cms xml encrypt although latter might good general purpos format instead uuid i would strong suggest use well seed prng java jce sha1prng creat ae key i dont see strong reason reli someth like uuid scheme ae key suppos consist random bit enough entropi think password lead trap cannot use string secur ae key the user trust applic server act trust third parti send user password server send incorrect public key user etc etc etc your scheme protect man middl attack mani argu cannot done without use ssl instead direct encrypt password look someth like password base encrypt pbkdf2 encrypt rsa privat key tri add integr protect encrypt javaonward may use ae gcm mode well worth \n",
      "**************************************************\n",
      "Document8\n",
      "Index: 490\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 15321911\n",
      "rest api token authent i start develop first rest api net sinc stateless i use token authent basic idea systemsecuritycryptographi ae encrypt hmacsha256 integr token data consist object properti usernam date issu timeout databas hold usernam hash password hmac hash login check credenti valid usernam compar hash password db valu true encrypt data object use hmac generat token store databas return token without hmac user cookiestr request method requir authent user send token request token decrypt expir error expir use hmac compar usernam generat hash db valu db check valid user authent the way i see approach follow pros even db comprosmis contain actual token hash cannot revers even attack token cannot increas expir updat field sinc expir date token now first i wonder good approach besid i still didnt figur store ae sha256 key server hardcod if i put webconfig use machin key i problem case load balanc server and last i store ae iv vector sinc cryptocreateencryptor requir decrypt doe mean user send token iv request i hope make sens i thank answer advanc updat ok i research came solut token contain origin specifi data usernam date issu timeout token generat encryptthenmac includ ae encrypt data iv vector tag thesevalu authent generat hmacsha265 token tag written db user authent tag valid token authent data decrypt token expir yet tag match one written databas user block databas token invalid demand key store webconfig separ section same key everi server per applic cours i didnt use formsauthenticationticket net follow issu key use differ purpos machinekey view state resourc formauthticket macthenencrypt use net consid safe encryptthenmac built way invalid token expir  this follow comment thread question you seem bit confus exact oauth hope i clarifi oauth web servic someth consum it protocol describ way site authent user servic without allow site know user credenti as side benefit oauth provid also web servic queri user inform permiss grant time typic interest implement oauth perspect site eg acmewidgetscom user log via facebook googl someth howev also implement servic side eg facebook normal would allow other authent you so exampl let say web servic allow thirdparti site provis acmebrand widget user your first thirdparti implementor popular mybookorg the flow would look someth like someon invit user use acm widget app mybook profil the user click button redirect acmewidgetscom the url look someth like this known oauth danc note number implement defin thing like url mean encod various token whether token expir revok etc hope clear everyth \n",
      "**************************************************\n",
      "Document9\n",
      "Index: 522\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 1501763\n",
      "use md5 generat encrypt key password im write simpl program file encrypt most academ exercis possibl futur serious use all heavi lift done thirdparti librari put piec togeth secur manner still quit challeng noncryptograph basic ive got everyth work way i think im use 128bit ae encrypt 128bit key length i want user abl enter variablelength password i decid hash password md5 use hash key i figur acceptableth key alway suppos secret there reason worri collis attack now ive implement i ran across coupl articl indic bad idea my question if good password chosen cipher suppos strong enough never reveal key except via extraordinari read current infeas bruteforc effort right should i use someth like pbkdf2 generat key overkil extrem cryptograph applic  well post general let state general thing md5 sha0 sha1 broken hash use cryptograph purpos use sha2 you general use wellknown document approach derriv key password dont mention languag pleas say one use when sort secur program import thing anyth strict document threat model this basic list attack tri prevent also sort attack cant prevent it quit fun youll get learn attack interest thing  this articl key strengthen might help basic want make key stronger entropi password make deriv password reliabl time consum  the answer new question definit use someth like pbkdf2 generat key i assum go password leastchar upper lower number punctuat right generat aes256 key the key use encryptdecrypt file you want use someth like pbkdf2 order decreas abil someon get file figur keypassword brute forc attack use someth like pbkdf2 random salt increas cost break encrypt file what i realli recommend use toy protect someth realli care if secur expert go make mistak even expert lot togeth make mistak httpwwwsslshoppercomarticlesslandtlsrenegotiationvulnerabilitydiscoveredhtml \n",
      "**************************************************\n",
      "**************************************************\n",
      "[RQ1] Topic2 - Example documents\n",
      "**************************************************\n",
      "Document0\n",
      "Index: 408\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 14288603\n",
      "what doesor didvolatil void function ive seen how mani usag volatil keyword c function grammar perspect use volatil keyword function clear explan casefrom question onli statement one respond seem pointlessuseless yet i cannot quit accept statement sinc ae softwar implement gnuc use liter year number function like this would allow compil recogn fatal go return but scenario doesnt appear appli ae code it long time sinc i anyth assembl i think id recogn jump someth like  the c99 standard say the properti associ qualifi type meaning express lvalues114th implement may place may use i idea cant realli specul the ae code your look probabl old cruft never got clean id guess  accord gcc document februari function tell compil function never return  refer httpsgithubcomnmoinvazminizipblobmasteraesaesviaaceh see linesthroughand linesthrough there plenti place find code first one i trip httpwwwopenstdorgjtc1sc22wg14docsrrdr113html thank ouah httpopencoresorgocsvnopenriscopenrisctrunkgnuoldbinutils21850gastestsuitegasi386padlockd turn search f3 0f a7 identifi opcod special encrypt oper gccs info document evid attribut function theoret exact effect in practic aint broke dont fix desir extens use techniqu definit discourag first depend custom compil second depend compil chang handl return case third potenti confus subsequ maintain the situat someth like make sens your take advantag high special machin code achiev otherwis imposs improv speed even balanc tradeoff in exampl precis two compil support machin specif hardwar support take advantag otherwis handl standard c code that lot effort make sure go pay \n",
      "**************************************************\n",
      "Document1\n",
      "Index: 586\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 512106\n",
      "misunderstand mixcolumn step im issu understand mixcolumn step describ i know diffus make sens point state column treat polynomi multipli modulo gf28 butmultipli gf28 although domain still revers due mod revers entir point as far first bit goe approach take abc d thebyt column a1 a2 a8 bit efg h output byte i go set and thus revers onetoon linear distribut it later state view matrix multipl element matrix must byte output byte element matrix must moduloand therefor revers non linear have i understood wrong i struggl math tri understand need done i convert logic  the multipl mixcolumn inde revers modulosamiamorgmixcolumnhtml good explan mixcolumn step samiamorggaloishtml excel job explain arithmet aess finit field  mixcolumn probabl hardest part ae excit work math actual see number came i work math detail blog post a stick figur guid advanc encrypt standard ae specif look actscenei also put revers crib sheet next sceneif question feel free leav comment post \n",
      "**************************************************\n",
      "Document2\n",
      "Index: 1400\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 28907297\n",
      "zero memori ae secretkeyspec key java i use java ae encrypt use generat key object after i encrypt someth i want remov key memori i remov refer key guarante key float somewher memori i zero byte array i use generat key i zero flush actual key memori  there doesnt appear way java version tobut fix javabi ad interfac see httpsbugsopenjdkjavanetbrowsejdk6263419 addess requir enhanc javasecurityprivatekey javaxcryptosecretkey class extend javaxsecurityauthdestroy interfac howev note comment clear biginteg byte refer doesnt guarante sensit inform gone memori the oper system virtual memori may swap disk exampl leav copi local hard drive in addit java runtim vm may multipl intern copi inform note also zero origin byte array not clear secretkeyspec take copi byte array constructor howev might abl get access secretkeyspec copi byte array even though privat use java reflect chang access field  if javaisnt avail your go need littl creativ name pick correct tool job in case id recommend c c give complet access actual memori java abstract almost away so explan would follow obtain memori address object this taken use code use memori address pass c program you creat variabl memori address manual zero memori address as point comment implement level detail aris the point answer highlight languag much better might worth look \n",
      "**************************************************\n",
      "Document3\n",
      "Index: 1720\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 22652351\n",
      "measur run time program nano second im suppos measur run time code test various file size encrypt howev i think method i use mere output current timer cpu run time program this code implement i dont think i correct  im confus first thing absolut correct main method doesnt wrote it print cpu time sinc epoch comput actual walltim the easiest way chang program creat method function main method simpli insert initi part here excerpt i strong caution though may accur there two thing need wari tri time thingswil os assum data alreadi ram andwil architectur assum data alreadi cach if run mani time like run speed ram speed readingwrit disk to truli get averag speed need ensur os readwrit disk may requir mani intermedi dummi readingwrit \n",
      "**************************************************\n",
      "Document4\n",
      "Index: 2158\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 47456386\n",
      "how generat small encrypt output aroundbyt fromcharact abyt key is algorithm method encryptcharact use abyt key encrypt string size remain less thancharact i tri use ae deflat final encrypt string quit larg respect expect string length thank  first youd need tri compress encrypt if ae deflat mean encrypt compress never get compress encrypt data effect random compressor second even wouldnt general expect much compress justcharact compressor need data look pattern third would get factor ofcompress anyth high redund data even lot data  technic could depend definit charact for exampl might think use u0308 combin diaeresi combin diacrit interest keep pile diacrit so still four charact kind extra codepoint noel the text four charact iscod point ad diacrit get inform per charact next fact unicod larg alphabet if expand alphabet plane encod lot inform it like base64 base195088 for inform cram lot inform charact see stackexchang code challeng encod imag tweet extrem imag compress edit base stackoverflow twitter encod challeng twitter imag encod challeng this high depend havecharact orbyt  the algorithm describ key hash truncat hmacsha256 fit specif use thefirst byte produc hash but cours irrevers \n",
      "**************************************************\n",
      "Document5\n",
      "Index: 2372\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 41703167\n",
      "rijndael mixcolumn algorithm number less 0x1b wikipedia c program wrong i start implement aesbit algorithm fpga gather inform i found c algorithm wiki want check mixcolumn step work i think calcul mod oper right way the program perform  rewritten clariti correct modulo oper short answer whi modulo oper examin one bit bit0x80 the oper question implement gf28 multipl when expand byte individu bit fpga implement i sure whether one expand express individu output bit straightforward id person write awk script someth hard work whether use intermedi state reduc size lookup tabl i havent opportun play fpgas yet \n",
      "**************************************************\n",
      "Document6\n",
      "Index: 2379\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 23942785\n",
      "massiv perform improv gvsvsin aesni ive work time comparison cpu aesni gpu ae recent ive updat g compil fromtoand saw signific increas perform 2x cpu aesni i simplifi c code simul ae encrypt use aesni instruct list bellow this code 1gb bufin data amd 5400k serial execut yield follow g46 real 0m2982s user 0m2466s sys 0m0433s g47 real 0m1453s user 0m0877s sys 0m0512s g48 real 0m1157s user 0m0592s sys 0m0468s i generat assembl version g47and found compil replac set instruct type movdqamovq movdqu see pictur bellow httppostimgorgimageq6j8qwyol is safe assum improv doe make sens whi gnot consid instruct first place  3 thing i notic affect perform the1 better copi data in old gcc appear break 16b copi into8b loadsstor this probabl unalign instruct use terribl perform micro code older architectur after intel nehalem processor unalign instruct made fast align instruct assum cach split compil therefor tri take advantag liber use unalign instructionslook like gcc optim away buffer overrun check contribut overhead havent look detail whyalso look like optim away need dynam align stack pointer 32b need first case could use movdqa need second case therefor probabl perfbug optim away third case \n",
      "**************************************************\n",
      "Document7\n",
      "Index: 2841\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 2751213\n",
      "separ binari encrypt data doe binari encrypt string could contain space carriag return what best way put separ two encrypt byte array  there concept binari data general you could defin particular byte byte sequenc separ youd work escap rule case data occur natur it general better idea includ length prefix multipl valu might length ofor equal invalid valu asid anyth els make much easier read data scan separ you read data next chunk valu whatev without accident read next valu pass stream whatev need read next lengthvalu pair  shouldnt need way separ string sinc know string bebit take string break block ofbit  probabl problem want use encrypt data somewher want hold encrypt data string origin data string also then solut easi you convert byte string respect function convert data back binari \n",
      "**************************************************\n",
      "Document8\n",
      "Index: 2919\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 21225963\n",
      "aesctr mode bit shift creat counter i access vc sourc code i tri convert vbnet i previous ask question regard bit shift although answer given made sens seem rather simpl convert vbnet i difficulti get thing work here vc code i need convert vbnet etc etc or i misinterpret someth somewher  not sure your expect c code but i use start right byte expand left carryov for instanc counter reachescounter7 hold 231he7 counter6 3h3 look whole array give h000000000003e7 equalsdecim  someth tell convers better done use getbyt touint64 method loop temporari variabl it would much easier read probabl fast enough purpos \n",
      "**************************************************\n",
      "Document9\n",
      "Index: 3130\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 39357146\n",
      "numpi implement ae signific slower pure python i look reimplement slowa code httpanhcslucedu331codeaespi tri take advantag nativ array support numpi im get counterintuit result pure python slowa much much faster function implement use numpi here clearest exampl i one main oper ae shift row row 4x4 element byte array shift number positionsfor row1 rowetc the origin python code treat 4x4 byte state array one dimension 16element list use slice creat virtual row rotat howev timeit show execut time ofmicrosecond i hope numpi optim array oper might result somewhat faster code where i go wrong and approach would result faster ae implement pure python there intermedi result i want get pycrypto may applic though go slow i may take second looksep thank answer to answer question im look run hundr thousand million sampl plaintextciphertext pair so time differ singl encrypt make littl differ time save i get could make huge differ long run  the simpl answer there lot overhead creat array so oper small list usual faster equival one array that especi true array version iter like list one for larg array oper use compil method faster theserol time illustr for small list final index array \n",
      "**************************************************\n",
      "**************************************************\n",
      "[RQ1] Topic3 - Example documents\n",
      "**************************************************\n",
      "Document0\n",
      "Index: 63\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 2697667\n",
      "creat cerif bounci castl encrypt i tri creat selfsign certif use encrypt email use bouncycast what would best way generat certif i tri use openssl i problem certif here code i use encrypt i use 3des this thrown i call smimeenvelopedgeneratorgener method i current attach sourc code eclips see i get use error messag step code  i would use keytool openssl generat selfsign certif if problem post dont say problem if want generat certif java code use orgbouncycastlex509x509v3certificategener class  you okay openssl command i would use generat selfsign cert openssl req x509 node daysnewkey rsa1024 keyout mycertpem mycertpem this creat file call mycertpem contain privat key self sign cert note exampl key unencrypt okay test purpos both key cert pem encod includ standard header footer line \n",
      "**************************************************\n",
      "Document1\n",
      "Index: 1473\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 30106966\n",
      "smartcard pkcs11 ae key gen failur i attempt creat aeskey acos564 smartcard omnikeycard reader use pkcs11 python use pykcs11 librari so far standard oper seem work regard asymmetr crypto i run plenti code sampl pkcs11tool command initi token setchang pin creat rsa keypair etc so driver function pcscd ccid pkcs11 middlewar the follow code caus problem the thing i switch ckatoken line fals work of cours set fals make key session object instead token object ie i logout key wipe use pkcs11tool listobject key i use acscmu gui tool token admin i creat ae key secret key manag creat persist key but i way see acscmu make persist may use pkcs11 if i guess problem id guess session if ckatokentru invalid seem token actual rw mode suggest ckfrwsession 9th line so far im sure els tri debug  imo noth contact produc flag set respons this flag indic whether mechan perform devic softwar  figur ton dig ton exampl ckaid requir attribut go make persist ckatokentru object not sure i suppos know never saw document inde work beauti ive ad this code work driver setup proper \n",
      "**************************************************\n",
      "Document2\n",
      "Index: 2691\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 40071588\n",
      "how get ssl certif local websit i want get ssl certif webpag chat i also use aeshash algorithm deal secur webpag data use sha512 password hash but dont know get ssl certif industri level i tri mani give free ssl websit still havent got what server signatur get thank  this realli server admin question program issu you either self sign certif get one certif author self sign certif secur but mani time program languag dont like or connect someth use need tell function selfsign ok that said want real certif may want look let encrypt httpsenwikipediaorgwikilet27sencrypt  you need creat keystor set ssl enabl one after creat keystor sign certif author exampl go daddi globalsign but test purpos need creat selfsign certif use keytool come jdk jre cprogram filesjavajdk18060binkeystoolex you creat selfsign certif use command keytool genkey dname cnservernam ouabc ocompanycom lmorrisvill snc cus alia myalia keyalg rsa validitykeysizekeystor keystorejk storepass password keypass password here storepass keypass avoid confus now creat keystorejk time server configur i consid use apach tomcat use server find server configur easili tutori you need edit two file serverxml setenvshbatgo catalinahomeconf here find serverxml edit port inform communic go ssl enabl port you need creat one connector defaultport like here specifi path generat keystor file keystorefil attribut keystorepass equal password chosen creat keystor filego catalinahomebin here find setenvshbat file here need specifi keystor password path keystor file add server environ variabl insid javaopt djavaxnetsslkeystorekeystorekeystorejk djavaxnetsslkeystorepasswordpassword i hope give direct configur purpos \n",
      "**************************************************\n",
      "Document3\n",
      "Index: 3011\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 8667334\n",
      "protect public rsa key transit clarif my question relat set secur communic channel two parti key read passphras agre upon real world onli use rsa allow mitmattack im misstaken i think encrypt public key ae key agre upon send respect parti im current tri build two applic talk eachoth to secur exchang messag i think use rsa applic set key befor communic start two applic need exchang key that shouldnt problem i think use ae encrypt public key send internet i know word public public key mean i think would see right applicationcomput get key one els so i want exchang key protect mitm attack if anybodi could give better suggest im use libcrypto librari btw im ear thank best regard toma gustavsson  this question show mani misconcept part i know word public public key mean i think would see right applicationcomput get key one els i think real problem ask which i think how know use public key entiti actual want communic public key malici entiti claim want communic this problem solv typic instal certif sign trust author issu specif entiti ie ip dns name in case havent given detail certif you could well manual preinstal use secur connect if follow plan eg symmetr encrypt would start ask question eg secur share secret key etc \n",
      "**************************************************\n",
      "Document4\n",
      "Index: 3342\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 53893371\n",
      "text messag encrypt end end use ae end end encrypt android im tri implement chat applic android i tri ae algorithm encrypt decrypt success generat privat public key generatersakeypairjava class generat public privat key tri im expect privat key public specif userbut code im build applic generat differ privat public key everi time would i manag current user previous chat messag data everi time oneon chate group chat also answer suggest would appreci  store privat key object x509 cours hint x509 certif specif key encod compat binari format public key dont need much protect long trust attack abl replac public key cours how trust public key topic entir book key manag for asymmetr key usual use pki public key infrastructur distribut valid status key wrap public key certif when x509 certif use pki often refer pkix tls certif browser part larg pkix system \n",
      "**************************************************\n",
      "Document5\n",
      "Index: 4834\n",
      "CsvFileName: bouncycastle.csv\n",
      "post_link_id: 22230745\n",
      "generat selfsign certif fli i search around i didnt find clear exampl i want creat selfsign selftrust certif programmat c follow step stepcreat root ca certif fli add certif store folder trust root certif author i want exact command line tool  i edit answer root certif first issu end entiti certif here exampl generat selfsign certif bounci castl i compil exampl code wakeupneo comment wakeupneo might slight edit code add proper extens certif  ok thank help here work code  we use follow code test nuget depend bounci castl  so long time i refin answer my origin task creat certif fli wcf servic my window servic applic wcf servic i want creat channel runtim creation associ certif present local machin all code right way there one piec miss you creat certif embed export privat key see link this focus critic part snippet generat privat key  after integr chang multipl post i final got code work \n",
      "**************************************************\n",
      "Document6\n",
      "Index: 4843\n",
      "CsvFileName: bouncycastle.csv\n",
      "post_link_id: 7230330\n",
      "sign csr use bounci castl i cannot find codedoc describ sign csr use bc as input i csr byte array would like get cert pem andor der format i gotten far i troubl figur get certif generat store pem der format or i go wrong path togeth  ok i look stuff life i couldnt figur the api talk generat key pair generat cert sign csr somehow quit chanc here i found sinc pkcs10 repres format request csr first need put csr pkcs10holder then pass certificatebuild sinc certificategener deprec the way pass call getsubject holder here code java pleas adapt need as see ive generat request outsid method pass then i pkcs10certificationrequesthold accept constructor arg next x509v3certificatebuild argument youll see pk10holdergetsubject appar need if someth miss pleas let know it work the cert i generat correct dn info i need wikipedia killer section pkcs httpenwikipediaorgwikipkc  archi thank i made chang code see the main chang pass issuer name use public key csr  the follow code base answer compil given pem encod csr kind export keytool return valid pemencod signeddata object contain sign certif chain type import keytool oh bouncycastl  mike b test exampl thorough i get strang behavior code im use bc15on version when i sign client request self sign ca i import ie show certif valid ca chain howev see import ff imag right ca chain miss ff cannot verifi trust author also ie ff attempt authent web server fail http cannot verifi trust author ive made chang code suit need general anyon give pointer onto im wrong updat ok case solv thank thread obvious use cacertgetsubjectx500principalgetnam i got name issuer revers broke chain use instead certgetsubjectx500principalgetencod solv so ca get verifi upto trust author make sure get name correct  in end work \n",
      "**************************************************\n",
      "Document7\n",
      "Index: 4855\n",
      "CsvFileName: bouncycastle.csv\n",
      "post_link_id: 2457795\n",
      "x509 certif valid java bouncycastl bouncycastl wiki page i abl understand creat x509 root certif certif request i quit understand proceed concept program wise let assum parti a cert request get client certif ca how parti b valid as certif what kind certif a need a root certif a normal client certif and valid work program level assum a success send certif der pem format b ani help much appreci best regard rob  ok idea behind cas follow cas peopl everyon trust to end select trust cas avail browseremail clienteven mobil in case public root key certif applic user send request ca certif pem format public key cas i leav ambigu deliber form verif end user charg money case enhanc verif green cert background check if ca doesnt think user request valid communic somehow if sign public key produc certif contain inform this process certreq turn x509 cert other user come across fictiti user want know trust so take look certif find digit sign someon trust list so fact trust root ca root ca could sign via privat key user public key ca trust user deduc new user trust mr fictiti on programmat level implement read x509 certif work ca suppos given cas fingerprint find databas verifi signatur if match chain trust this work ive said ca creat digit signatur anyon verifi it exact revers encrypt concept what encrypt privat key data wish sign verifi decrypt public key equal data youv got  from programm perspect need thing valid x509 certif a set trust anchorsth root certif cas reli these protect tamper attack doesnt replac ca certif fake the public key certif use verifi digit signatur certif a collect intermedi certif the applic might keep collect protocol like ssl smime use certif standard way provid extra certif store doesnt requir special care integr protect signatur root ca revoc inform even certif issu ca might revok prematur privat key disclos end entiti chang ident for exampl person switch job certif old compani name revok crls webservic like ocsp use get updat status certif with input avail use builtin pkix support construct valid certif path an import thing note path cannot found dont get much inform reason this frustrat way design in general mani potenti path if fail differ reason would path builder decid report reason \n",
      "**************************************************\n",
      "Document8\n",
      "Index: 4865\n",
      "CsvFileName: bouncycastle.csv\n",
      "post_link_id: 3625624\n",
      "insert certif privatekey root localmachin certif store fail net 4 im problem insert new ca certif privatekey root certif store localmachin this happen it cute but it wrongstupid dog refer and certif export dialog give fine messag this code run imperson administr use snippet click id love know whi test window serverr2 windowsil damn it work i compil v35 what  it seem import key littl way see httpsupportmicrosoftcomkb950090 exampl moreov i find good save privat key moreov consid remov privat key direct usag import realli need use hold perman all import better secur  i encount problem seem even user run findprivatekey tool access key therefor would get unabl obtain privat key file name messag you could run tool localsystem process more inform httpwwwitsolutionbraindumpscom201102findingprivatekeyforyourhtml dinko  i exact problem solut turn realli simpl all i pass i hope help  new x509certificate2localpfxpath inputpass x509keystorageflagsmachinekeyset x509keystorageflagspersistkeyset instead work  usual certif root wont privat key manag you import my folder associ key web request i tlsssl except i chain client certif if store chain certif my store i got rid except where problem user account util store certif use current user account actual applic run system account  the basic problem net certif api wrapper around c advapi32 certif manag api dont get specifi option get pass api actual respons stick cert window cert store persist key the bottom line usemachinestor option need get pass cspproviderflag turn get pass capicryptmachinekeyset this littl guy determin whether key get persist real there seem sever differ reason option doesnt get set even though set x509keystorageflagspersistkeyset machinekeyset export all option live long stupid key stay cprogramdatamicrosoftcryptorsamachinekey folder if cryptmachinekeyset doesnt get set time import advapi32 blow key away soon certif handl get dispos gc solut add certif trust root befor import certif person machin store in read log capi2 i actual see two call x509 object everi time certif import one alway note i found unneccessari use certif subject key identifi alreadi somehow trigger api actual generat ski instead hand trigger condit pass magic cryptmachinekeyset flag advapi32 \n",
      "**************************************************\n",
      "Document9\n",
      "Index: 4866\n",
      "CsvFileName: bouncycastle.csv\n",
      "post_link_id: 12501117\n",
      "programmat obtain keystor pem how one programmat obtain keystor pem file contain certif privat key i attempt provid client certif server https connect i confirm client certif work i use openssl keytool obtain jks file i load dynam i even get work dynam read p12 pkcs12 file im look use pemread class bouncycastl i cant get past error im run java client djavaxnetdebugal option apach web server debug loglevel im sure look though the apach error log indic  i figur the problem x509certif isnt suffici i need put privat key dynam generat keystor well it doesnt seem bouncycastl pemread handl pem file cert privat key one go handl piec separ i read pem memori break two separ stream feed one separ pemread sinc i know pem file im deal cert first privat key second i simplifi code cost robust i also know end certif delimit alway surround five hyphen the implement work \n",
      "**************************************************\n",
      "**************************************************\n",
      "[RQ1] Topic4 - Example documents\n",
      "**************************************************\n",
      "Document0\n",
      "Index: 108\n",
      "CsvFileName: 3des.csv\n",
      "post_link_id: 1492118\n",
      "which librari would consid linux dea data encrypt algorithm i need 3des encryptdecrypt librari project do know implement work linux linux target platform i essanti compiledebug window therefor could realli appreci could work window mandatori  look eric young libd this librari also use window well linux  openssl reput well test open sourc secur librari it avail nix window you find edit cant find simpl exampl right the api document pretti good though there precompil version window avail download openssl site most packag manag prepackag version openssl linux box shouldnt compil version  compil libcrypto openssl window i wouldnt recommend httpwwwpixelbeatorgprogramminglibcryptohtml mayb nss use firefox would use httpwwwmozillaorgprojectssecuritypkinss though id probabl tri someth simpl like httpwwwlysatorliusenissenettlenettlehtml  i use botan i realli like it implement 3des lot other algorithm it c api object orient i like featur might disagre it support lot system window linux freebsd etc lot processor x86 x8664 ia64 powerpc compil it seem good perform final licens allow commerci develop at least worth look \n",
      "**************************************************\n",
      "Document1\n",
      "Index: 260\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 1179672\n",
      "how avoid instal unlimit strength jce polici file deploy applic i app use 256bit ae encrypt support java box i know get function correct i instal jce unlimit strength jar secur folder this fine develop i instal my question sinc app distribut end user like polici file instal have end user download make app function attract solut is way make app run without overwrit file end user machin a third parti softwar handl without polici file instal or way refer polici file within jar  dure instal program prompt user dos batch script bash shell script download copi jce proper system locat i use server webservic instead formal instal i provid script setup app user could run you make app unrunn run setup script you could also make app complain jce miss ask download restart app  for applic client server architectur allow decryptingencrypt data server level henc jce file need we anoth problem need updat secur jar client machin jnlp overwrit librari jvm first run that made work  for altern cryptographi librari look bounci castl it ae lot ad function it liber open sourc librari you use lightweight proprietari bounci castl api work though  bounci castl still requir jar instal far i tell i littl test seem confirm httpwwwbouncycastleorgwikidisplayja1frequentlyaskedquest  there coupl common quot solut problem unfortun neither entir satisfactori instal unlimit strength polici file while probabl right solut develop workstat quick becom major hassl roadblock nontechn user instal file everi comput there way distribut file program must instal jre directori may even readon due permiss skip jce api use anoth cryptographi librari bounci castl this approach requir extra 1mb librari may signific burden depend applic it also feel silli duplic function includ standard librari obvious api also complet differ usual jce interfac bc implement jce provid doesnt help key strength restrict appli hand implement this solut also wont let use 256bit tls ssl cipher suit standard tls librari call jce intern determin restrict but there reflect is anyth cant use reflect still keep reportingand 256bit tls cipher suit wont work this code work oracl javaandand automat skip process javaand openjdk need be ugli hack like doesnt work vendor vms it also doesnt work oracl javabecaus privat jce class obfusc the obfusc chang version version though still technic possibl support java here solut httpmiddlesphere1blogspotru201406thiscodeallowstobreaklimitifhtml  you could use method test avail key length use inform user go someth state applic fall back tobit key due polici file instal exampl secur conscious user instal polici file other continu use weaker key  as jdk 8u102 post solut reli reflect longer work field solut set httpsbugsopenjdkjavanetbrowsejdk8149417 look like back either use bounci castl b instal jce polici file  this longer need javanor recent releas java7 orfin per jdk8170157 unlimit cryptograph polici enabl default specif version jira issu java10etc ani offici releas java 8u161 later avail java 7u171 later onli avail my oracl support java 6u181 later onli avail my oracl support note odd reason old behavior need javait set use  here updat version ntoskrnl answer it addit contain function remov final modifi like arjan mention comment this version work jre 8u111 newer  here modifi version ntoskrnl code featur \n",
      "**************************************************\n",
      "Document2\n",
      "Index: 275\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 3862800\n",
      "invalidkeyexcept illeg key size i test run great develop macbook pro fail run continu integr teamciti server the error follow updat look like accord select answer i modifi someth teamciti instal possibl affect user instal good choic i switch anoth crypto librari without limit so probabl bounci castl help updatei actual switch use bouncycastl avoid limit note work use bc class direct bc provid  this error mean java virtual machin use polici allow restrict cryptographi key size due us export law javaand higher the unlimit strength jurisdict polici file includ javaand use default see secur updat javamigr guid if get error javait might mean polici configur chang restrict polici note jdk jrelibsecur the new polici file take effect restart jvm especi import longrun server process like tomcat  in addit instal polici file also make sure get firstbyt better yet use whole secret key deriv key ae size need  i similar problem case path error javahom jdk16018 i put two jar  make sure know path javahom ide use in order copi correct path in case i use intellij libraryjavajavavirtualmachinesjdk180112jdkcontentshomejrelibsecur instead show javahom consol usersmyusersdkmancandidatesjavacurrentjrelibsecur  i face issu jdkfor version need download jar file relat securitybecaus localpolicyjar usexportpolicyjar alreadi includ version path jrelibsecuritypolici javahom refer current java instal folder the chng need make javasecur file present jrelibsecur uncom line cryptopolicyunlimit \n",
      "**************************************************\n",
      "Document3\n",
      "Index: 429\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 12956037\n",
      "gssexcept encrypt type aes256ct mode hmac sha196 supporteden after set domain user support ae encrypt kerbero token window server 2008r2 webappl server side get follow except gssexcept failur unspecifi gssapi level mechan level encrypt type aes256ct mode hmac sha196 supporteden strang java16027 mean ae support accord document httpdocsoraclecomjavase6docstechnotesguidessecurityjgssjgssfeatureshtml ani idea what miss webappl java third parti we use spring secur kerbero extens minim code modif fit current spring 2x version addit authent requir  editupcom jdk version includ onli config paramet need set see jdk8157561 follow link java se download scroll download java cryptographi extens jce unlimit strength jurisdict polici file specif jdk version follow process tutori titledkerbero unlimit strength polici the basic step follow locat jdks secur directori show unix restart anyth that make use jdk tomcat etc \n",
      "**************************************************\n",
      "Document4\n",
      "Index: 541\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 26345175\n",
      "correct way freealloc context openssl iam use open ssl program encrypt decrypt data use ae cipher at moment littl memori leak im look way fix in encrypt decrypt routin context free like  you use hand explicit scrub inform free memori least make decent attempt i presum so need call function youv suppli key materi  allright think clear if createfre context deprec  first want precis answer alway specifi version openssl use fyii current long term support version whilei newest septif read theman page notic evpcipherctx made opaqu openssla result evpcipherctxreset appear evpcipherctxcleanup disappear evpcipherctxinit remain alia evpcipherctxreset short answer use here good explan \n",
      "**************************************************\n",
      "Document5\n",
      "Index: 589\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 15551158\n",
      "is aes256 encrypt decrypt possibl java without unlimit strength jce file the project i work segment requir ae encrypt decrypt from possibl internet sourc i could look hard find refer aes256 encrypt without download instal unlimit strength jce file sun oracl websit besid whatev legal issu exist distribut help us practic come ask end user visit particular websit download file put directori add thing classpath window etc there refer internet bountycastl lightweight api possibl didnt requir jce file i couldnt look relev refer exampl demonstr not sure problem everi program languag if possibl aesbit encrypt without particular jce file instal jni approach help to elabor bit aesencrypt done cc i call use jni desir result would packag softwar jar file caus concern issu anoth import factor come play project would run mac window limit use cc specif compilerinterpret version anyth is differ way handl ani approach  first problem everi program environ openssl written c support larg key exampl from experi jce jni i would howev suggest find way use pure java instead load nativ librari jni it lot easier a practic solut is applic instal use kind instal applic instal if one solut could use instal also instal jce bouncycastl unfortun also use jce state faq updat i found librari might look it doesnt seem maintain longer howev httpwwwcryptixorg updategnu librari implement aes256 httpwwwgnuorgsoftwaregnucrypto more avail cipher httpwwwgnuorgsoftwaregnucryptomanualciphershtml code exampl use gnucrypto given alreadi key load  the key size restrict implement implement class may contain within jca provid cannot posit influenc allow key size you direct use implement class \n",
      "**************************************************\n",
      "Document6\n",
      "Index: 975\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 9027467\n",
      "sslsocket ae encrypt we need use ae encrypt client server communic i enabl cipher suit tlsdhersawithaes128cbcsha sslservetsocket use javaand run program get except no avail certif key correspond ssl cipher suit enabl my question ae encrypt sslsocket need regular socket if cant use anyon pleas provid exampl client server communic use ae encrypt here code thank advanc  the anonym cipher suit dont perform authent even encrypt your talk encrypt channel remot parti cant sure could man middl mitm the tlsspecif say follow anonym cipher suit the follow cipher suit use complet anonym diffiehellman communic neither parti authent note mode vulner maninthemiddl attack therefor deprec in short dont use except test perhap your realli sure wont activ mitm the tlsspecif even strong word usag if want use tls secur youll need way client verifi ident remot parti in vast major case done use x509 certif in particular relat system properti there topic answer exampl httpsstackoverflowcoma6341566372643   no avail certif key correspond ssl cipher suit enabl this error mean either privat keyscertif suitableaccept cipher suit enabl this like mean eg short key length configur certif \n",
      "**************************************************\n",
      "Document7\n",
      "Index: 997\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 30259466\n",
      "jcek keystor longer load comsuncryptoprovidersealedobjectforkeyprotector i jcek keystor hold ae key this work dev environ gae runtim last night i deploy updat noth crypto case load keystor throw ioexcept comsuncryptoprovidersealedobjectforkeyprotector subsequ none crypto work youd expect given i cant get key ive googl except one lead look promis convert key jcek provid anoth store anoth provid suggest keytor creat one provid cannot read anoth provid doesnt seem case work yesterday also httpsaccessredhatcomdocumentationenusjbossenterpriseapplicationplatform62htmladministrationandconfigurationguidesectpasswordvaultsforsensitivestringshtml suggest incompat provid i roll back app previous work version i get error has gae chang default provid should i explicit declar requir provid code thank steve updat root caus identifi the problem ioexcept thrown ksload googl class name found sourc possibl actual sourc line number stack trace align linesuggest ioexcept thrown result classnotfoundexcept messag name class wasnt found case comsuncryptoprovidersealedobjectforkeyprotector httpwwwdocjarcomhtmlapicomsuncryptoproviderjcekeystorejavahtml so root caus googl app engin runtim v1921 cannot load keystor cannot load class comsuncryptoprovidersealedobjectforkeyprotector googl admit whitelist issu temporari resolut as result support ticket googl revert runtim back towhich doesnt problem im await fix allow get back onto autom engin updat updat resolv googl fix v1922 runtim updat not resolv the problem persist v1922 runtim updat realli resolv proven googl fix v1923 runtim answer updat reflect  this confirm fix gae runtimenot miss cut the problem runtim whitelist omit one class need load jcek keystor this problem affect gae runtimesnot server engin version sdk version you check server version consol \n",
      "**************************************************\n",
      "Document8\n",
      "Index: 1293\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 24328239\n",
      "dotnetzip zipinputstream issu i use dotnetziplibrari face problem use bzip2 aes256 forentri withinarch zipoutputstream work fine zipinputstream get wrong bzip2 header if i use commom deflat algorithm everyth fine i creat zipoutputstream file stream ani idea  this probabl hint problem like gzip bzip2 data compressor it archiv like tar zip program facil multipl file encrypt archivesplit unix tradit reli instead separ extern util tar gnupg task sourc wikipedia  i know quit old topic may still use someon googl solut ive notic order invok compress properti setter import with \n",
      "**************************************************\n",
      "Document9\n",
      "Index: 1625\n",
      "CsvFileName: aes.csv\n",
      "post_link_id: 43857083\n",
      "doe compil crypto librari code use aesgcm encrypt util intel aesni instruct im implement aes256gcm encrypt authent use crypto librari my code compil use visual studioa cmfc project this somewhat older project use previous version librari  if run code contain aesni instruct x86 hardwar support instruct get invalid instruct error unless code someth smart look cpuid decid whether run aesni optim code someth els also use detect whether aesni instruct actual use otherwis alway use debugg set breakpoint aesni instruct see whether process ever use portion code accord crypto releas note aesni support ad versionlook sourc code versioncrypto aesni support enabl compil time use runtim check function probabl util cpuid decid whether use intrins see rijndaelcpp cpucpp cpuid code sourc code detail   im curious result compil code use intel aesni instruct cryptoad support aesni carryless multipli gcm it use two three condit met first use version librari support from homepag news readm versionreleas ad support aesni clmul instruct set ae gmacgcm second compil assembl linker must support instruct for crypto mean use least msvcsp1 gccand binutilsfor msvc look you may better luck observ low level detail windbg it also worth mention aesgcm sped interleav ae gcm i believ idea performround ae key calcul andclmul parallel crypto take advantag openssl take opportun i dont know botan mbedtl  just finish question here find the method fork execut hardwar support encrypt seem fast even without hardwar ae support \n",
      "**************************************************\n",
      "**************************************************\n",
      "[RQ1] Topic5 - Example documents\n",
      "**************************************************\n",
      "Document0\n",
      "Index: 72898\n",
      "CsvFileName: keystore.csv\n",
      "post_link_id: 4262773\n",
      "keytool sign problem keystor tamper password incorrect i tri sign releas version android app debug sign fine googl map api i posit password correct i tri export app eclips ask keystor password i enter correct not sure i cant sign i need display googl map releas mode work debug mode  i dont think includ storepass your list the storepass encrypt privat key isnt display list just tri then provid keystor password prompt if work tri keypass command line you might also want check make sure use version java i dont think that problem doesnt help tri  i problem jarsign jdk16031 i switch back tojarsign work correct pleas awar jdk version  check alia name some time alia differ keytool alia name give error ie  somehow window keytool would accept password i need sha1 password configur client id project googl dev consol the follow seem work this print sha1 key alias   machin wherea window machin need enter list keystor \n",
      "**************************************************\n",
      "Document1\n",
      "Index: 73399\n",
      "CsvFileName: keystore.csv\n",
      "post_link_id: 39821487\n",
      "tri renam packag android studio say file com alreadi exist i creat new app android studio everyth went fine i creat sign apk i old app play store publish i manag locat keykeystor old app origin eclips two year ago open old apk keystor explor i abl rememb old store password alia key password i went back android studio click generat new sign apk i select old keystor path fill info store password alia key password left generat new sign apk old keykeystor im assum i actual got new as app sign old eclips keykeystor wouldnt left generat sign apk right run emul i enter correct info now next problem im renam packag i need renam new apppackag name old apppackag comnameradio i read buildgradl when i creat new app as i abl renam thefold java first problem nameieradio i select folder i want renam click show option menu untick compact empti middl packag right click folder select refactor renam renam packag i correct buildgradl work fine first time now i want renam new app packag name old app comnameradio i tri set new packag name com doesnt allow say file alreadi exist httpistackimgurcomcnga5png should i delet com folder appbuildgeneratedsourcerreleas there point tri renam buildgradl yet right someon help like guess everi night i want publish updat old app without publish fresh app  this modif need three step chang packag name manifest refactor name packag right click refactor renam tree view android studio display window select renam packag chang manual applic id buildgradl file android defaultconfig applic id then clean rebuild project accord answer    all need delet directori android studio say caus problem in case directori it affect sourc code sinc directori automat generat rebuild project \n",
      "**************************************************\n",
      "Document2\n",
      "Index: 73609\n",
      "CsvFileName: keystore.csv\n",
      "post_link_id: 44687596\n",
      "jarign unabl open jar file i search lot issu everyth ive found didnt seem help i tri sign cordova app android follow command i specifi directori apk keystor default directori i also tri place apk file folder keystor file i got error pleas help  mycent use window tri command prompt bash tool it fix  anoth way open project android studio go build generat sign apk go next page click choos exist button import keystor file type password alia keystor file go next page select signatur version method click finish button \n",
      "**************************************************\n",
      "Document3\n",
      "Index: 74443\n",
      "CsvFileName: keystore.csv\n",
      "post_link_id: 44610252\n",
      "key store alia im tri upload game googl ive alreadi upload version one i jump frustrat hoop get versionsign it wont allow creat key store alia whatev inform ive put game compani comdefaultcompanyblast sky abov name i fill inform i get certif error ive restart project this frustrat thing ive ever spent well overhour tri figur could someon run tri get sign apk right certif i upload game thank  i believ set key store path apk file instead jks file shown android doc kept safe directori time sinc keystor provid access apk releas process that said may need releas new apk new keystor jks file yes mean publish new list app play consol \n",
      "**************************************************\n",
      "Document4\n",
      "Index: 100705\n",
      "CsvFileName: sha.csv\n",
      "post_link_id: 31834433\n",
      "googl map api key releas build doesnt work im current develop applic android im use googl map api in develop consol i ad sha1 certif print follow packag name even though i put sha1 certif print use keytool i cant access map i made lot search everi topic brought answer error wrong api key develop consol but i took right sha1 one certif thank advanc  i problem super frustrat what i end take key i made use releas keystor put googl develop consol then ad follow android manifest im sure read document make sure follow instruct releas certif dot httpsdevelopersgooglecommapsdocumentationandroidsignup you could also follow link generat googlemapsapixml file this autom process enter key develop consol howev make sure still add meta data valu manifest  the file googlemapsapixml resdebug resreleas the editor show current run configur debug default bit mislead observ debug note folder name copi googlemapsapixml folder edit make sure correct api key ofr build  android studio also creat todo releas folder googlemapsapi xml file let know requir procedur releas also pleas chang key manifest manual when switch releas variant key automat updat manifest in case go link mention andrew brook click get key continu either creat new project use exist one specifi option click button if alreadi made one let say debug go creat new api key imag add requir name click add packag name fingerprint add app packag name sha1 key generet use keytool javajdkbin imag you get releas variant api key ad googlemapsapixml releas folder  my map releas mode show i publish play store show i mention debug releas certif sha1 key googl develop consol map releas mode download app play store still show here problem googl play app sign enabl app goto releas manag app sign copi sha1 certif fingerprint app sign certif past newli copi sha1 fingerprint develop consol map releas mode show  you enabl sha key in googl develop consol 1st go releas manag get app sha key 1st one follow link now will enabl api updat app new key it work \n",
      "**************************************************\n",
      "Document5\n",
      "Index: 101629\n",
      "CsvFileName: sha1.csv\n",
      "post_link_id: 34933380\n",
      "sha1 key debug releas android studio mac how i get sha1 key debug releas use android studio mac these requir googl api key  debug click gradl tab right hand side view go root folder task android signingreport doubl click build signingreport post bottom view sha1 releas in android studio build generat sign apk click next copi key store path key alia travers bin folder jdk path present java open termin enter keytool list v keystor key store path alia key alia enter key password print releas sha1  to obtain sha1 debug well releas add key detail signingconfig gradl file see exampl  here new easiest way find releas sha1 certif i assum alreadi built sign apk upload develop consol open googl play consol go version manag go applic sign see certif note first googl ask activ applic sign applic \n",
      "**************************************************\n",
      "Document6\n",
      "Index: 101671\n",
      "CsvFileName: sha1.csv\n",
      "post_link_id: 25867876\n",
      "android sha1 releas keystor work googl map i use googl map android api im run issu i sign apk android studio creat one androidkeystorejk also im select releas type i use command file creat new api key api consol ad releas sha1 key ad api key app made full clean rebuild generat new sign apk file it work updat a friend mine tri reproduc issu he exact issu work android studio probabl android studio bug  1 usual clean rebuild project work make sure build variant releas android studio friend thisalso debug devic fulli uninstal first continu as document say make sure set manifest correct hope help  creat new project android studio googl map activ after project automat creat sha1 manifest use sha1 get map api key test app sure work and build app project  sha1 current use debug purpos so creat sign apk u one kestor file tri generat new sha1 key new keaystor file use keystor file creat api key sign apk googl consol replac debug api key alreadi store manifest file new one it work thank  you two googlemapsapixml file one folder appsrcdebugresvalu other folder appsrcreleaseresvalu but debug one contain api key probabl  you also need add sha1 generat googl app sign certif onc publish app find googl play consol develop tool releas manag app sign app sign certif more detail googl place android api key work app play store \n",
      "**************************************************\n",
      "Document7\n",
      "Index: 102591\n",
      "CsvFileName: sha1.csv\n",
      "post_link_id: 20692005\n",
      "googl map report invalid key android i got sha1 fingerprint use keytool applic key i sign applic i upload play store but i open app phone test say right key ani idea i could wrong not sure inform give without give secur info app help give anymor inform i think pleas let help help  have tri remov applic instal this key might got cach even instal applic new key so instal applic new key tri remov applic complet phone you well go blog post i wrote make sure step right produc key googl map api v2 key  first develop generat sha1 debugkeystor navig cprogram filesjavajdk160bin bin locat execut command now get one sha1 certif generat api key googl api consol replac key manifestxml file now app readi publish market this may help \n",
      "**************************************************\n",
      "**************************************************\n",
      "[RQ1] Topic0 - Tag Counter\n",
      "**************************************************\n",
      "3des.csv: 223, aes.csv: 3388, bouncycastle.csv: 449, cng.csv: 13, crypto++.csv: 225, cryptoapi.csv: 88, cryptographic-hash-function.csv: 5, cryptography.csv: 4185, cryptojs.csv: 564, des.csv: 352, diffie-hellman.csv: 43, digital-signature.csv: 117, ecdsa.csv: 16, elliptic-curve.csv: 40, encryption-asymmetric.csv: 119, encryption-symmetric.csv: 269, encryption.csv: 9825, hash.csv: 694, hmac.csv: 491, jce.csv: 85, keystore.csv: 44, md5.csv: 361, openssl.csv: 1547, pbkdf2.csv: 99, pkcs#11.csv: 15, pkcs#7.csv: 84, private-key.csv: 121, public-key-encryption.csv: 329, public-key.csv: 95, pycrypto.csv: 333, rijndael.csv: 277, rsa.csv: 1604, salt.csv: 56, sha.csv: 155, sha1.csv: 283, sha256.csv: 377, smartcard.csv: 35, x509.csv: 27, x509certificate.csv: 34, xor.csv: 120\n",
      "**************************************************\n",
      "[RQ1] Topic1 - Tag Counter\n",
      "**************************************************\n",
      "3des.csv: 7, aes.csv: 496, bouncycastle.csv: 23, cng.csv: 16, crypto++.csv: 12, cryptoapi.csv: 21, cryptographic-hash-function.csv: 14, cryptography.csv: 1953, cryptojs.csv: 61, des.csv: 33, diffie-hellman.csv: 28, digital-signature.csv: 89, ecdsa.csv: 5, elliptic-curve.csv: 5, encryption-asymmetric.csv: 90, encryption-symmetric.csv: 133, encryption.csv: 8229, hash.csv: 3359, hmac.csv: 184, jce.csv: 11, keystore.csv: 121, md5.csv: 961, openssl.csv: 229, pbkdf2.csv: 122, pkcs#11.csv: 5, private-key.csv: 86, public-key-encryption.csv: 189, public-key.csv: 47, pycrypto.csv: 17, rijndael.csv: 31, rsa.csv: 218, salt.csv: 746, sha.csv: 215, sha1.csv: 307, sha256.csv: 231, smartcard.csv: 36, x509.csv: 34, x509certificate.csv: 54, xor.csv: 20\n",
      "**************************************************\n",
      "[RQ1] Topic2 - Tag Counter\n",
      "**************************************************\n",
      "3des.csv: 3, aes.csv: 202, bouncycastle.csv: 52, cng.csv: 4, crypto++.csv: 55, cryptoapi.csv: 22, cryptographic-hash-function.csv: 15, cryptography.csv: 1762, cryptojs.csv: 36, des.csv: 56, diffie-hellman.csv: 31, digital-signature.csv: 108, ecdsa.csv: 11, elliptic-curve.csv: 43, encryption-asymmetric.csv: 7, encryption-symmetric.csv: 25, encryption.csv: 2898, hash.csv: 14490, hmac.csv: 59, jce.csv: 4, keystore.csv: 34, md5.csv: 1692, openssl.csv: 433, pbkdf2.csv: 19, pkcs#11.csv: 9, pkcs#7.csv: 7, private-key.csv: 22, public-key-encryption.csv: 52, public-key.csv: 23, pycrypto.csv: 16, rijndael.csv: 12, rsa.csv: 339, salt.csv: 77, sha.csv: 355, sha1.csv: 479, sha256.csv: 348, smartcard.csv: 74, x509.csv: 38, x509certificate.csv: 66, xor.csv: 1111\n",
      "**************************************************\n",
      "[RQ1] Topic3 - Tag Counter\n",
      "**************************************************\n",
      "3des.csv: 7, aes.csv: 76, bouncycastle.csv: 970, cng.csv: 55, crypto++.csv: 48, cryptoapi.csv: 171, cryptography.csv: 2287, cryptojs.csv: 40, des.csv: 7, diffie-hellman.csv: 64, digital-signature.csv: 1730, ecdsa.csv: 237, elliptic-curve.csv: 176, encryption-asymmetric.csv: 123, encryption-symmetric.csv: 22, encryption.csv: 1845, hash.csv: 155, hmac.csv: 115, jce.csv: 65, keystore.csv: 738, md5.csv: 37, openssl.csv: 3198, pbkdf2.csv: 2, pkcs#11.csv: 377, pkcs#7.csv: 222, private-key.csv: 620, public-key-encryption.csv: 532, public-key.csv: 416, pycrypto.csv: 45, rijndael.csv: 2, rsa.csv: 1584, sha.csv: 53, sha1.csv: 90, sha256.csv: 138, smartcard.csv: 1197, x509.csv: 1144, x509certificate.csv: 1800, xor.csv: 1\n",
      "**************************************************\n",
      "[RQ1] Topic4 - Tag Counter\n",
      "**************************************************\n",
      "3des.csv: 11, aes.csv: 325, bouncycastle.csv: 523, cng.csv: 25, crypto++.csv: 191, cryptoapi.csv: 74, cryptographic-hash-function.csv: 3, cryptography.csv: 1180, cryptojs.csv: 71, des.csv: 21, diffie-hellman.csv: 66, digital-signature.csv: 223, ecdsa.csv: 24, elliptic-curve.csv: 39, encryption-asymmetric.csv: 15, encryption-symmetric.csv: 35, encryption.csv: 3267, hash.csv: 1212, hmac.csv: 99, jce.csv: 188, keystore.csv: 519, md5.csv: 295, openssl.csv: 6226, pbkdf2.csv: 24, pkcs#11.csv: 114, pkcs#7.csv: 28, private-key.csv: 176, public-key-encryption.csv: 141, public-key.csv: 205, pycrypto.csv: 236, rijndael.csv: 11, rsa.csv: 447, salt.csv: 102, sha.csv: 144, sha1.csv: 145, sha256.csv: 135, smartcard.csv: 203, x509.csv: 199, x509certificate.csv: 413, xor.csv: 22\n",
      "**************************************************\n",
      "[RQ1] Topic5 - Tag Counter\n",
      "**************************************************\n",
      "aes.csv: 91, bouncycastle.csv: 18, crypto++.csv: 1, cryptoapi.csv: 1, cryptography.csv: 81, cryptojs.csv: 10, des.csv: 1, diffie-hellman.csv: 1, digital-signature.csv: 67, ecdsa.csv: 1, encryption-asymmetric.csv: 1, encryption-symmetric.csv: 4, encryption.csv: 768, hash.csv: 193, hmac.csv: 2, jce.csv: 5, keystore.csv: 727, md5.csv: 78, openssl.csv: 81, pkcs#11.csv: 3, pkcs#7.csv: 3, private-key.csv: 48, public-key-encryption.csv: 11, public-key.csv: 9, pycrypto.csv: 2, rsa.csv: 36, salt.csv: 4, sha.csv: 39, sha1.csv: 183, sha256.csv: 11, smartcard.csv: 6, x509.csv: 3, x509certificate.csv: 23, xor.csv: 5\n",
      "**************************************************\n",
      "[RQ2] Topic0 - Calculated popularity variables\n",
      "**************************************************\n",
      "ViewCountAvg: 632.5110768759516\n",
      "CommentCountAvg: 0.6368460408839879\n",
      "FavoriteAvg: 0.26796219717650027\n",
      "ScoreAvg: 0.43120985251853655\n",
      "**************************************************\n",
      "[RQ2] Topic1 - Calculated popularity variables\n",
      "**************************************************\n",
      "ViewCountAvg: 464.43669648729247\n",
      "CommentCountAvg: 0.4279394938601944\n",
      "FavoriteAvg: 0.19930268385632044\n",
      "ScoreAvg: 0.45654387055506007\n",
      "**************************************************\n",
      "[RQ2] Topic2 - Calculated popularity variables\n",
      "**************************************************\n",
      "ViewCountAvg: 605.1078047154427\n",
      "CommentCountAvg: 0.583592349342775\n",
      "FavoriteAvg: 0.20696054848329234\n",
      "ScoreAvg: 0.6657206951539231\n",
      "**************************************************\n",
      "[RQ2] Topic3 - Calculated popularity variables\n",
      "**************************************************\n",
      "ViewCountAvg: 634.5132120687947\n",
      "CommentCountAvg: 0.3127832283755417\n",
      "FavoriteAvg: 0.20148292296188186\n",
      "ScoreAvg: 0.48903123507842555\n",
      "**************************************************\n",
      "[RQ2] Topic4 - Calculated popularity variables\n",
      "**************************************************\n",
      "ViewCountAvg: 506.2747461643107\n",
      "CommentCountAvg: 0.31086425759254754\n",
      "FavoriteAvg: 0.13104858689874502\n",
      "ScoreAvg: 0.41401118949160787\n",
      "**************************************************\n",
      "[RQ2] Topic5 - Calculated popularity variables\n",
      "**************************************************\n",
      "ViewCountAvg: 78.72083029271062\n",
      "CommentCountAvg: 0.044956169986576214\n",
      "FavoriteAvg: 0.024910583168914476\n",
      "ScoreAvg: 0.06368640593889925\n",
      "**************************************************\n",
      "[RQ3] Topic0 - AnswerCount / ViewCount\n",
      "**************************************************\n",
      "Value: 0.0005491773222298365\n",
      "**************************************************\n",
      "[RQ3] Topic1 - AnswerCount / ViewCount\n",
      "**************************************************\n",
      "Value: 0.0006543024898799405\n",
      "**************************************************\n",
      "[RQ3] Topic2 - AnswerCount / ViewCount\n",
      "**************************************************\n",
      "Value: 0.0007328353955461218\n",
      "**************************************************\n",
      "[RQ3] Topic3 - AnswerCount / ViewCount\n",
      "**************************************************\n",
      "Value: 0.00039380049682046745\n",
      "**************************************************\n",
      "[RQ3] Topic4 - AnswerCount / ViewCount\n",
      "**************************************************\n",
      "Value: 0.00044758447988003485\n",
      "**************************************************\n",
      "[RQ3] Topic5 - AnswerCount / ViewCount\n",
      "**************************************************\n",
      "Value: 0.00040834189386406794\n",
      "**************************************************\n",
      "[RQ3] Topic0 - Average Response Time\n",
      "**************************************************\n",
      "Value: 907128.3825267304\n",
      "14216\n",
      "**************************************************\n",
      "[RQ3] Topic1 - Average Response Time\n",
      "**************************************************\n",
      "Value: 1049116.6068158697\n",
      "9830\n",
      "**************************************************\n",
      "[RQ3] Topic2 - Average Response Time\n",
      "**************************************************\n",
      "Value: 756949.3974126617\n",
      "16001\n",
      "**************************************************\n",
      "[RQ3] Topic3 - Average Response Time\n",
      "**************************************************\n",
      "Value: 1791112.1471967597\n",
      "9382\n",
      "**************************************************\n",
      "[RQ3] Topic4 - Average Response Time\n",
      "**************************************************\n",
      "Value: 2377867.669159641\n",
      "7354\n",
      "**************************************************\n",
      "[RQ3] Topic5 - Average Response Time\n",
      "**************************************************\n",
      "Value: 2284840.5005586594\n",
      "895\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import matplotlib.pyplot as plt;\n",
    "import numpy as np\n",
    "\n",
    "no_top_words = 20\n",
    "no_features = 1000\n",
    "no_topics = [6]\n",
    "n_grams = [1]\n",
    "\n",
    "def displaytopics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "\n",
    "class TagCounter:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.counter = 1\n",
    "        \n",
    "    def addOne(self):\n",
    "        self.counter = self.counter + 1\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.name) + \": \" + str(self.counter)\n",
    "\n",
    "\n",
    "class TagCounterList:\n",
    "    def __init__(self):\n",
    "        self.myList = []\n",
    "        \n",
    "    def addTagCounterOrApply(self, name_p):\n",
    "        for e in self.myList:\n",
    "            if (e.name == name_p):\n",
    "                e.addOne()\n",
    "                return\n",
    "        self.myList.append(TagCounter(name_p))\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \", \".join([str(elem) for elem in self.myList])\n",
    "        \n",
    "    \n",
    "    \n",
    "# Iterate over number of topics\n",
    "for number_topics_iter in no_topics:\n",
    "    print (\"Now calculating: \" + str(number_topics_iter) + \" number of topics\")\n",
    "    print(\"Preparing LDA ...\")\n",
    "    lda = LatentDirichletAllocation(n_components=number_topics_iter,\n",
    "                                    max_iter=5,\n",
    "                                    learning_method='online',\n",
    "                                    random_state=0,\n",
    "                                    doc_topic_prior=0.13333333333333333,\n",
    "                                    topic_word_prior=0.2,\n",
    "                                    learning_decay=0.7,\n",
    "                                    learning_offset=50.)\n",
    "    \n",
    "    for gram in n_grams:\n",
    "        \n",
    "        \n",
    "        print (\"Now using \" + str(gram) + \"gram with TFIDF-Vectorizer\")\n",
    "        vectorizer_tfidf = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english', ngram_range = (gram,gram))\n",
    "        fit_transformed_documents_tfidf = vectorizer_tfidf.fit_transform(documents)\n",
    "        result_tfidf = lda.fit(fit_transformed_documents_tfidf)\n",
    "        \n",
    "        print (\"****************************************\")\n",
    "        print (\"[RQ1] LDA topics - TFIDF, \" + str(number_topics_iter) + \" topics, \" + str(gram) + \"gram\")\n",
    "        print (\"****************************************\")\n",
    "        displaytopics(result_tfidf, vectorizer_tfidf.get_feature_names(), no_top_words)\n",
    "        print (\"****************************************\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        # rows: documents, columns: topics\n",
    "        # [document][topic]\n",
    "        doc_topic = lda.transform(fit_transformed_documents_tfidf)\n",
    "        print (doc_topic)\n",
    "        topics_counter = [0 for i in range(0, number_topics_iter)]\n",
    "        \n",
    "        ten_documents_per_topic = [[] for i in range(0, number_topics_iter)]\n",
    "        \n",
    "        \n",
    "        # vars RQ2\n",
    "        viewCount_sum = [0 for i in range(0, number_topics_iter)]\n",
    "        commentCount_sum = [0 for i in range(0, number_topics_iter)]\n",
    "        favoriteCount_sum = [0 for i in range(0, number_topics_iter)]\n",
    "        score_sum = [0 for i in range(0, number_topics_iter)]\n",
    "        \n",
    "        # Topic Tag List\n",
    "        topic_tag_list = [TagCounterList() for i in range(0, number_topics_iter)]\n",
    "        \n",
    "        # vars RQ3\n",
    "        answerCount_sum = [0 for i in range(0, number_topics_iter)]\n",
    "        timeDelay_sum = [0 for i in range(0, number_topics_iter)]\n",
    "        timeDelayCount = [0 for i in range(0, number_topics_iter)]\n",
    "        \n",
    "        \n",
    "        # For every document\n",
    "        for n in range (doc_topic.shape[0]):\n",
    "            \n",
    "            # Get the most fitting topic\n",
    "            topic_most_pr = doc_topic[n].argmax()\n",
    "            \n",
    "            # Increase the topic counter by 1\n",
    "            topics_counter[topic_most_pr] = topics_counter[topic_most_pr]+1\n",
    "            \n",
    "            # Grab some example topic files\n",
    "            if (doc_topic[n][topic_most_pr] > 0.9):\n",
    "                if (len(ten_documents_per_topic[topic_most_pr]) < 10):\n",
    "                    ten_documents_per_topic[topic_most_pr].append(n)\n",
    "            \n",
    "            # Change vars [RQ2]\n",
    "            viewCount_sum[topic_most_pr] = viewCount_sum[topic_most_pr]+documents_addons[n].viewCount\n",
    "            commentCount_sum[topic_most_pr] = commentCount_sum[topic_most_pr]+documents_addons[n].commentCount\n",
    "            favoriteCount_sum[topic_most_pr] = favoriteCount_sum[topic_most_pr]+documents_addons[n].favoriteCount\n",
    "            score_sum[topic_most_pr] = score_sum[topic_most_pr]+documents_addons[n].score\n",
    "            \n",
    "            # Change vars [RQ3]\n",
    "            answerCount_sum[topic_most_pr] = answerCount_sum[topic_most_pr]+documents_addons[n].answerCount\n",
    "            if (documents_addons[n].responseTimeInSeconds != 0):\n",
    "                timeDelay_sum[topic_most_pr] = timeDelay_sum[topic_most_pr] + documents_addons[n].responseTimeInSeconds\n",
    "                timeDelayCount[topic_most_pr] = timeDelayCount[topic_most_pr]+1\n",
    "            \n",
    "            # TagCounterList\n",
    "            splittedFileName = documents_addons[n].csvFileName.split('\\\\')\n",
    "            topic_tag_list[topic_most_pr].addTagCounterOrApply(splittedFileName[len(splittedFileName)-1])\n",
    "        \n",
    "        for n in range(0, number_topics_iter):\n",
    "            print (\"**************************************************\")\n",
    "            print (\"[RQ1] Topic\" + str(n) + \" - Example documents\")\n",
    "            print (\"**************************************************\")\n",
    "            \n",
    "            for ex_doc in range(0, len(ten_documents_per_topic[n])):\n",
    "                print (\"Document\" + str(ex_doc))\n",
    "                print (\"Index: \" + str(ten_documents_per_topic[n][ex_doc]))\n",
    "                splittedFileName = documents_addons[ten_documents_per_topic[n][ex_doc]].csvFileName.split('\\\\')\n",
    "                print (\"CsvFileName: \" + splittedFileName[len(splittedFileName)-1])\n",
    "                print (\"post_link_id: \" + str(documents_addons[ten_documents_per_topic[n][ex_doc]].post_link_id))\n",
    "                print (\"responseTimeInSeconds: \" + str(documents_addons[ten_documents_per_topic[n][ex_doc]].responseTimeInSeconds))\n",
    "                print (\"viewCount: \" + str(documents_addons[ten_documents_per_topic[n][ex_doc]].viewCount))\n",
    "                print (\"commentCount: \" + str(documents_addons[ten_documents_per_topic[n][ex_doc]].commentCount))\n",
    "                print (\"favoriteCount: \" + str(documents_addons[ten_documents_per_topic[n][ex_doc]].favoriteCount))\n",
    "                print (\"score: \" + str(documents_addons[ten_documents_per_topic[n][ex_doc]].score))\n",
    "                print (\"answerCount: \" + str(documents_addons[ten_documents_per_topic[n][ex_doc]].answerCount))\n",
    "                \n",
    "                print (documents[ten_documents_per_topic[n][ex_doc]])\n",
    "                print (\"**************************************************\")\n",
    "        \n",
    "        for n in range (0, number_topics_iter):\n",
    "            print (\"**************************************************\")\n",
    "            print (\"[RQ1] Topic\" + str(n) + \" - Tag Counter\")\n",
    "            print (\"**************************************************\")\n",
    "            print(topic_tag_list[n])\n",
    "        \n",
    "        \n",
    "        \n",
    "        for n in range (0, number_topics_iter):\n",
    "            print (\"**************************************************\")\n",
    "            print (\"[RQ2] Topic\" + str(n) + \" - Calculated popularity variables\")\n",
    "            print (\"**************************************************\")\n",
    "            \n",
    "            print (\"ViewCountAvg: \" + str(viewCount_sum[n] / doc_topic.shape[0]))\n",
    "            print (\"CommentCountAvg: \" + str(commentCount_sum[n] / doc_topic.shape[0]))\n",
    "            print (\"FavoriteAvg: \" + str(favoriteCount_sum[n] / doc_topic.shape[0]))\n",
    "            print (\"ScoreAvg: \" + str(score_sum[n] / doc_topic.shape[0]))\n",
    "            \n",
    "            \n",
    "        \n",
    "        for n in range (0, number_topics_iter):\n",
    "            print (\"**************************************************\")\n",
    "            print (\"[RQ3] Topic\" + str(n) + \" - AnswerCount / ViewCount\")\n",
    "            print (\"**************************************************\")\n",
    "            if (viewCount_sum[n] == 0):\n",
    "                continue\n",
    "            print (\"Value: \" + str(answerCount_sum[n] / viewCount_sum[n]))\n",
    "            \n",
    "        \n",
    "        \n",
    "        for n in range (0, number_topics_iter):\n",
    "            print (\"**************************************************\")\n",
    "            print (\"[RQ3] Topic\" + str(n) + \" - Average Response Time (in seconds)\")\n",
    "            print (\"**************************************************\")\n",
    "            if (timeDelayCount[n] == 0):\n",
    "                continue\n",
    "            print (\"Value: \" + str(timeDelay_sum[n] / timeDelayCount[n]))\n",
    "            print (timeDelayCount[n])\n",
    "            \n",
    "        \n",
    "        objects = [\"Topic\"+str(i+1) for i in range(0, number_topics_iter)]\n",
    "        y_pos = np.arange(len(objects))\n",
    "        performance = topics_counter\n",
    "\n",
    "        plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "        plt.xticks(y_pos, objects)\n",
    "        plt.ylabel('no_documents')\n",
    "        plt.title('Number of documents per topic')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        print (\"Now using \" + str(gram) + \"gram with Count-Vectorizer\")\n",
    "        vectorizer_count = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english', ngram_range = (gram,gram))\n",
    "        fit_transformed_documents_count = vectorizer_count.fit_transform(documents)\n",
    "        result_count = lda.fit(fit_transformed_documents_count)\n",
    "\n",
    "        print (\"****************************************\")\n",
    "        print (\"LDA topics - CountVec, \" + str(number_topics_iter) + \" topics, \" + str(gram) + \"gram\")\n",
    "        print (\"****************************************\")\n",
    "        displaytopics(result_count, vectorizer_count.get_feature_names(), no_top_words)\n",
    "        print (\"****************************************\")\n",
    "        '''\n",
    "\n",
    "#pyLDAvis.sklearn.prepare(lda, tfidf_lda, tfidf_vectorizer_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA...\n",
      "vectorizer_tfidf...\n",
      "fit_transformed_documents_tfidf...\n",
      "GridSearch...\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programme_NoAdmin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1356565.922, total= 1.1min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1268231.833, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1250593.643, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  3.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1347761.840, total= 1.1min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1265768.529, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  5.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1249216.465, total= 1.1min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  6.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2, score=-1346174.624, total= 1.1min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  8.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2, score=-1261467.116, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  9.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2, score=-1248630.947, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 10.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1349408.213, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1262454.942, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1250073.019, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1346055.248, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1260774.007, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1241449.208, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2, score=-1342020.305, total= 1.1min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2, score=-1260794.958, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2, score=-1236883.911, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1348846.544, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1266492.546, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1245452.826, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1345715.947, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1266523.951, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1243230.189, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2, score=-1342004.024, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2, score=-1260532.153, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2, score=-1239932.619, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1345545.861, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1262501.113, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1242011.121, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1343374.559, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1258770.047, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1237275.597, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2, score=-1338789.516, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2, score=-1254861.158, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2, score=-1236507.196, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1348011.963, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1262914.858, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1243158.272, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1344032.734, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1262009.937, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1237136.152, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2, score=-1343479.483, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2, score=-1261483.336, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2, score=-1236941.705, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1344354.976, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1257794.472, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1238062.740, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1338448.952, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1255666.085, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1236714.657, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2, score=-1342365.278, total= 1.2min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2, score=-1254927.862, total= 1.3min\n",
      "[CV] doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.13333333333333333, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2, score=-1235888.436, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1364457.275, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1275395.847, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1265157.844, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1355136.647, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1272799.271, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1256043.057, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2, score=-1352258.611, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2, score=-1271576.766, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2, score=-1254634.962, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1358151.860, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1273554.198, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1253867.956, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1352729.083, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1273051.147, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1252016.449, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2, score=-1350388.677, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2, score=-1271359.060, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2, score=-1249285.669, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1355927.675, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1272649.265, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1257884.233, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1353249.093, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1270495.833, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1250303.414, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2, score=-1345560.981, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2, score=-1269840.274, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2, score=-1254524.745, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1349099.636, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1268067.098, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1247306.069, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1347149.840, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1267137.548, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1245404.880, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2, score=-1346286.568, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2, score=-1265950.613, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2, score=-1244586.769, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1348077.889, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1273826.082, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1251467.731, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1345022.185, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1272174.395, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1248503.296, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2, score=-1342748.671, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2, score=-1271810.589, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2, score=-1247488.681, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1345194.388, total= 1.2min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1263070.259, total= 1.4min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1242476.774, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1343594.209, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1261513.056, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1241530.599, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2, score=-1344580.122, total= 1.3min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2, score=-1260660.825, total= 1.4min\n",
      "[CV] doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.16666666666666666, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2, score=-1240595.824, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1368763.787, total= 1.2min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1280254.846, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1270224.425, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1364989.112, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1271700.565, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1263348.548, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2, score=-1359583.398, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2, score=-1269669.145, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=10.0, topic_word_prior=0.2, score=-1257262.998, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1362547.916, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1271173.911, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1264419.562, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1361214.158, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1269781.854, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1252020.890, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2, score=-1360002.265, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2, score=-1271070.122, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.6, learning_offset=50.0, topic_word_prior=0.2, score=-1249292.471, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1360687.865, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1270532.881, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1252709.122, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1359239.539, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1268253.064, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1251146.200, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2, score=-1356859.355, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2, score=-1267788.171, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=10.0, topic_word_prior=0.2, score=-1249515.223, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1356046.702, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1269898.272, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1249136.837, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1355770.551, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1269100.850, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1247116.687, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2, score=-1354155.317, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2, score=-1266490.479, total= 1.5min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.7, learning_offset=50.0, topic_word_prior=0.2, score=-1245994.292, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1356167.091, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1273777.710, total= 1.5min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.13333333333333333, score=-1259656.723, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1355706.361, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1272133.225, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.16666666666666666, score=-1259192.396, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2, score=-1354026.670, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2, score=-1271821.510, total= 1.5min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=10.0, topic_word_prior=0.2, score=-1251862.450, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1352306.702, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1266054.491, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.13333333333333333, score=-1246259.298, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1351502.972, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1265770.100, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.16666666666666666, score=-1245515.834, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2, score=-1351010.324, total= 1.3min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2, score=-1265186.439, total= 1.4min\n",
      "[CV] doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2 \n",
      "[CV]  doc_topic_prior=0.2, learning_decay=0.8, learning_offset=50.0, topic_word_prior=0.2, score=-1244594.488, total= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed: 206.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'doc_topic_prior': 0.13333333333333333, 'learning_decay': 0.7, 'learning_offset': 50.0, 'topic_word_prior': 0.2}\n",
      "Best Log Likelihood Score:  -1276719.657149451\n",
      "Model Perplexity:  916.7734868865173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n",
    "search_params = {'learning_decay': [.6, .7, .8],\n",
    "                 'doc_topic_prior': [0.13333333333333333, 0.16666666666666666, 0.2],\n",
    "                 'topic_word_prior': [0.13333333333333333, 0.16666666666666666, 0.2],\n",
    "                 'learning_offset': [10., 50.]}\n",
    "\n",
    "print(\"LDA...\")\n",
    "lda = LatentDirichletAllocation(n_components=6, max_iter=5, learning_method='online', random_state=0)\n",
    "    \n",
    "print(\"vectorizer_tfidf...\")\n",
    "vectorizer_tfidf = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "\n",
    "print(\"fit_transformed_documents_tfidf...\")\n",
    "fit_transformed_documents_tfidf = vectorizer_tfidf.fit_transform(documents)\n",
    "\n",
    "print(\"GridSearch...\")\n",
    "model2 = GridSearchCV(lda, param_grid=search_params, verbose=10)\n",
    "\n",
    "model2.fit(fit_transformed_documents_tfidf)\n",
    "\n",
    "best_lda_model = model2.best_estimator_\n",
    "\n",
    "print(\"Best Model's Params: \", model2.best_params_)\n",
    "print(\"Best Log Likelihood Score: \", model2.best_score_)\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(fit_transformed_documents_tfidf))\n",
    "\n",
    "os.system(r'%windir%\\system32\\rundll32.exe powrprof.dll,SetSuspendState Hibernate')\n",
    "\n",
    "#print (test.shape())\n",
    "\n",
    "#docsVStopics = pd.DataFrame(test, columns=[\"Topic\"+str(i+1) for i in range(no_topics)])\n",
    "#print (\"Created a (%dx%d) document-topic matrix.\" % (docsVStopics.shape[0], docsVStopics.shape[1]))\n",
    "#docsVStopics.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.system(r'%windir%\\system32\\rundll32.exe powrprof.dll,SetSuspendState Hibernate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 1}\n",
      "Best Log Likelihood Score:  -1200181.3096072844\n",
      "Model Perplexity:  639.3384648778841\n"
     ]
    }
   ],
   "source": [
    "best_lda_model = model2.best_estimator_\n",
    "\n",
    "print(\"Best Model's Params: \", model2.best_params_)\n",
    "print(\"Best Log Likelihood Score: \", model2.best_score_)\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(tfidf_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just a little text\n"
     ]
    }
   ],
   "source": [
    "class Doc_class:\n",
    "    def __init__(self, text, something):\n",
    "        self.text = text\n",
    "        self.something = something\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.text\n",
    "        \n",
    "        \n",
    "doc1 = Doc_class(\"just a little text\", \"anything else\");\n",
    "\n",
    "print(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3des.csv'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spliited = documents_addons[0].csvFileName.split('\\\\')\n",
    "spliited[len(spliited)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-18f5e0f55839>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtopic_tag_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-70-1fdfe8ed4872>\u001b[0m in \u001b[0;36m__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\": \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "print (topic_tag_list[0].myList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-b483e9f675c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtopic_tag_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-70-1fdfe8ed4872>\u001b[0m in \u001b[0;36m__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\", \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyList\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-1fdfe8ed4872>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\", \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyList\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-1fdfe8ed4872>\u001b[0m in \u001b[0;36m__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\": \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello: 1\n"
     ]
    }
   ],
   "source": [
    "class TagCounter2:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.counter = 1\n",
    "        \n",
    "    def addOne(self):\n",
    "        self.counter = self.counter + 1\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.name + \": \" + str(self.counter)\n",
    "    \n",
    "\n",
    "taggie = TagCounter2(\"hello\")\n",
    "print (taggie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
